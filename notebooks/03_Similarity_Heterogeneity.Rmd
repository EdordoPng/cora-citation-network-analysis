---
title: "Similarity and Hetrogeneity"
author: "Edoardo Diana"
date: "2025-11-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# Indice

  1 : Caricare le librerie e dati da usare

  2 : Analisi di Similarità

    2.1: Cosine Similarity

    2.2: Pearson Similarity

    2.3: Global Similarity
  
    2.4: Top coppie di paper simili

  3 : Analisi di Eterogeneità

    3.1: Shannon Entropy

    3.2: Simpson Diversity

    3.3: Rao Quadratic Entropy
    
  4 : Assortativity e Mixing Patterns

  5 : Confronto tra Similarità e Centralità

  6 : Conclusioni

## 1 : Caricare le librerie e dati da usare

Librerie

```{r}
library(igraph)
library(tidygraph)
library(ggraph)
library(dplyr)
library(ggplot2)
library(knitr)
```

Carico i dati ottenuti dall'esecuzione 02_Centrality_Analysis.

Andiamo ad aprire il grafo con le centralità.

```{r}

# Percorso file salvato
processed_dir <- "../data/processed"
graph_file <- file.path(processed_dir, "graph_with_centralities.RData")

# Carica il grafo
if (file.exists(graph_file)) {
  load(graph_file)
  cat("✓ Grafo caricato con successo!\n")
  
  # Verifica attributi disponibili
  cat("\n=== ATTRIBUTI NODI DISPONIBILI ===\n")
  print(vertex_attr_names(graph))
  
  cat("\n=== INFORMAZIONI GRAFO ===\n")
  cat("  • Nodi:", vcount(graph), "\n")
  cat("  • Archi:", ecount(graph), "\n")
  
} else {
  stop("ERRORE: File non trovato! Esegui prima il Notebook 02.")
}

```

## 2 : Similarità

Definizione Locale : 2 nodi i e j sono simili se condividono molti vicini.

## 2.1 : Cosine Similarity

L'idea è qui di lavorare con la matrice di Adiacenza del grafo diretto non pesato.

L'idea è di associare ogni nodo i con l'i-esima riga o colonna della matrice di Adiacenza (ottengo quindi un vettore Ai).

Nota che : 

  - La riga i-esima di A, indica quali nodi sono raggiunti da i (quali paper cita il paper i)
  - La colonna i-esima di A, indica quali nodi raggiungono i (quali paper citano il paper i)
  

La similarità Coseno tra 2 nodi i e j è ottenuta misurando il coseno dell'angolo tra i vettori Ai ed Aj.


Poichè il mio grafo è diretto, ho due scelte per misurare la similarità : 


### Opzione 1: Similarità Coseno basata su successori comuni (paper citati in comune)

Questo corrisponde a quanto i paper i e j citano la stessa letteratura.

```{r}
# A è la matrice di adiacenza (righe = from, colonne = to)
A <- as_adjacency_matrix(graph, sparse = FALSE)

# Prodotto A %*% t(A) → matrice con successori comuni
common_successors <- A %*% t(A)

# Out-degrees (somma per riga)
out_deg <- rowSums(A)

# Cosine similarity basata su successori
D_out <- diag(1 / sqrt(out_deg))
D_out[!is.finite(D_out)] <- 0  # gestisci nodi con out-degree = 0

S_cosine_out <- D_out %*% common_successors %*% D_out

rownames(S_cosine_out) <- V(graph)$name
colnames(S_cosine_out) <- V(graph)$name

```

```{r fig.width=12, fig.height=9, fig.align='center', warning=FALSE}


# Trasformo la matrice in tibble "long" con colonne Var1, Var2, similarity
similarity_df <- as.data.frame(as.table(S_cosine_out)) %>%
  rename(node_i = Var1, node_j = Var2, similarity = Freq)

# Filtra solo metà matrice senza diagonale (eviti duplicati)
top_pairs <- similarity_df %>%
  filter(as.character(node_i) < as.character(node_j)) %>%  # solo triangolo superiore
  arrange(desc(similarity)) %>%
  slice_head(n = 10)

# Visualizza tabella
kable(top_pairs, digits = 4, col.names = c("Paper 1", "Paper 2", "Cosine Similarity"))

```

```{r}

# Tengo solo valori nel range desiderato
similarity_values_filtered <- S_cosine_out[upper.tri(S_cosine_out)]
similarity_values_plot <- similarity_values_filtered[similarity_values_filtered > 0]
# similarity_values_plot <- similarity_values_filtered[]

df_sim_filtered <- data.frame(similarity = similarity_values_plot)

ggplot(df_sim_filtered, aes(x = similarity)) +
  geom_histogram(bins = 40, fill = "steelblue", color = "black", alpha = 0.8) +
  labs(
    title = "Distribuzione Cosine Similarity (>0 , predecessori comuni)",
    x = "Cosine Similarity",
    y = "Frequenza"
  ) +
  theme_minimal()
```

### Opzione 2: Similarità basata su predecessori comuni (paper che citano entrambi)

Questo corrisponde a quanto i paper i e j sono citati dalle stesse fonti.

```{r}
# Prodotto t(A) %*% A → matrice con predecessori comuni
common_predecessors <- t(A) %*% A

# In-degrees (somma per colonna)
in_deg <- colSums(A)

# Cosine similarity basata su predecessori
D_in <- diag(1 / sqrt(in_deg))
D_in[!is.finite(D_in)] <- 0

S_cosine_in <- D_in %*% common_predecessors %*% D_in

rownames(S_cosine_in) <- V(graph)$name
colnames(S_cosine_in) <- V(graph)$name

```

Mostriamo qui la top delle coppie di paper che hanno molti precedessori in comune (similarità coseno entrante tendente ad 1). 

```{r}
# Trasforma matrice in tibble long
similarity_df_in <- as.data.frame(as.table(S_cosine_in)) %>%
  rename(node_i = Var1, node_j = Var2, similarity = Freq)

# Filtro triangolo superiore senza diagonale (evita duplicati)
top_pairs_in <- similarity_df_in %>%
  filter(as.character(node_i) < as.character(node_j)) %>%
  arrange(desc(similarity)) %>%
  slice_head(n = 10)  # prendi top 

# Visualizza tabella
kable(top_pairs_in, digits = 4, col.names = c("Paper 1", "Paper 2", "Cosine Similarity"))
```
```{r}

# Estrai solo valori nel range desiderato
similarity_values_filtered <- S_cosine_in[upper.tri(S_cosine_in)]
similarity_values_plot <- similarity_values_filtered[similarity_values_filtered > 0]

df_sim_filtered <- data.frame(similarity = similarity_values_plot)

ggplot(df_sim_filtered, aes(x = similarity)) +
  geom_histogram(bins = 40, fill = "steelblue", color = "black", alpha = 0.8) +
  labs(
    title = "Distribuzione Cosine Similarity ( >0 , predecessori comuni)",
    x = "Cosine Similarity",
    y = "Frequenza"
  ) +
  theme_minimal()
```


Qui andiamo a tenere solo le coppie di nodi che hanno una similarità > 0 e < 1 (dunque tutte le coppie con 0 e 1 son eliminate).

Se prendessi le prime 500 coppie per simlarità massima, tutte queste hanno un 1.

Dunque ho tagliato via 

```{r fig.width=12, fig.height=9, fig.align='center', warning=FALSE}


# Step 1: Estrai top 500 coppie per cosine similarity (solo 0 < sim < 1)
similarity_df <- as.data.frame(as.table(S_cosine_in)) %>%
  rename(node_i = Var1, node_j = Var2, similarity = Freq) %>%
  filter(as.character(node_i) < as.character(node_j)) %>%
  filter(similarity > 0 & similarity < 1) %>%
  filter(similarity > 0) %>%
  arrange(desc(similarity)) %>% 
  slice_head(n = 500)

# Step 2: Crea il grafo pesato
sim_graph <- graph_from_data_frame(similarity_df, directed = FALSE)

# (facoltativo) Porta gli attributi categoria dal grafo originale, se presenti
if ("category" %in% colnames(nodes)) {
  V(sim_graph)$category <- nodes$category[match(V(sim_graph)$name, nodes$name)]
}

ggraph(sim_graph, layout = "fr") +
  geom_edge_link(aes(width = similarity), color = "steelblue", alpha = 0.6) +
  geom_node_point(aes(color = category), size = 5, alpha = 0.8) +
  #geom_node_text(aes(label = name), repel = TRUE, size = 2.5) +
  scale_edge_width(range = c(0.5, 3.5)) +
  theme_graph() +
  labs(
    title = "Top 500 coppie per cosine similarity (predecessori comuni)",
    width = "Cosine Similarity",
    color = "Categoria"
  )


```

##  2.2: Pearson Similarity

La similarità tra i nodi i e j è il coefficiente di correlazione tra i vettori Ai ed Aj.

Questa misura va da -1 ad 1.

Al numeratore della formula ho la covarianza tra Ai e Aj.

Una covarianza positiva tra i e j si verifica quando condividono più vicini di quanti ce ne aspettassimo. 

Una covarianza negativa tra i e j si verifica quando condividono meno vicini di quanti ce ne aspettassimo.


La correlazione di Pearson tra due nodi i e j misura quanto i loro pattern di connessioni siano linearmente correlati, tenendo conto della media dei loro vicini (a differenza della cosine similarity che non considera la media).

```{r}

# Matrice di adiacenza
A <- as_adjacency_matrix(graph, sparse = FALSE)

# ============================================================================
# 1. PEARSON SIMILARITY - Successori comuni (paper citati in comune)
# ============================================================================

S_pearson_out <- cor(t(A))
diag(S_pearson_out) <- 0
rownames(S_pearson_out) <- V(graph)$name
colnames(S_pearson_out) <- V(graph)$name

# ============================================================================
# 2. PEARSON SIMILARITY - Predecessori comuni (paper citanti in comune)
# ============================================================================

S_pearson_in <- cor(A)
diag(S_pearson_in) <- 0
rownames(S_pearson_in) <- V(graph)$name
colnames(S_pearson_in) <- V(graph)$name


```

Top coppie per Pearson 

```{r}


# Successori comuni

pearson_values_out <- S_pearson_out[upper.tri(S_pearson_out)]

# Filtra valori "significativi" (es. |pearson| > 0.1)
pearson_significant <- pearson_values_out[abs(pearson_values_out) > 0.1]

ggplot(data.frame(pearson = pearson_significant), aes(x = pearson)) +
  geom_histogram(bins = 50, fill = "violet", color = "black", alpha = 0.7) +
  scale_x_continuous(limits = c(-1, 1)) +
  labs(
    title = "Distribuzione della Pearson similarity sui successori comuni (|ρ| > 0.1) )",
    x = "Pearson similarity",
    y = "Frequenza"
  ) +
  theme_minimal()


# Predecessori comuni

pearson_values_in <- S_pearson_in[upper.tri(S_pearson_in)]

# Filtra valori "significativi" (es. |pearson| > 0.1)
pearson_significant <- pearson_values_in[abs(pearson_values_in) > 0.1]

ggplot(data.frame(pearson = pearson_significant), aes(x = pearson)) +
  geom_histogram(bins = 50, fill = "violet", color = "black", alpha = 0.7) +
  scale_x_continuous(limits = c(-1, 1)) +
  labs(
    title = "Distribuzione della Pearson similarity sui predecessori comuni (|ρ| > 0.1) )",
    x = "Pearson similarity",
    y = "Frequenza"
  ) +
  theme_minimal()


```

La maggior parte delle coppie di paper non condivide alcun predecessore (paper che li citano).

Quindi la correlazione di Pearson è esattamente zero o molto vicina a zero.

I 2 grafici mostrano quindi la distribuzione degli indici di similarità lungo tutte le coppie di paper.
E lo fanno di quelle sole coppie che hanno un indice di similarità |ρ| > 0.1

Solo poche centinaia/migliaia di coppie hanno predecessori in comune e quindi valori di Pearson non nulli.

In pratica: la rete è molto sparsa, quindi la distribuzione della Pearson similarity è dominata da zeri o valori vicini a zero

Dove ho correlazioni positive ho che : quando un paper cita uno, tende a citare anche l'altro.


Infine le similarità negative sono così poco rilevanti che vengon filtrate tutte (sono molto vicine allo 0).

Non ci sono "competizioni" tra paper nella citazione: citare un paper non esclude citarne un altro.

```{r}

pearson_values <- S_pearson_in[upper.tri(S_pearson_in)]
pearson_values <- pearson_values[!is.na(pearson_values)]

cat("Coppie con ρ < -0.1:", sum(pearson_values < -0.1), "\n")
cat("Coppie con ρ > 0.1:", sum(pearson_values > 0.1), "\n")
cat("Percentuale negativi significativi:", 
    round(100 * mean(pearson_values < -0.1), 4), "%\n")


```


##  2.3: Global Similarity

Qui consideriamo il fatto che 2 nodi possono essere simili in vari modi, ad esempio usando path più lunghi o magari per via indiretta.

Dunque 2 nodi potrebbero avere pochi vicini in comune ma esser comunque simili in modo globale.

La presenza di path, di qualsiasi lunghezza, tra nodi è un indizio di similarità, infatii i path più brevi contano di più.


Ho che 2 nodi i e j sono simili se i vicini di i sono simili a j.

Serve dapprima Normalizzare.
Ciò serve per garantire che il calcolo della global similarity abbia senso numerico, converga e sia interpretabile come una misura “globale”.

1. Matrice di adiacenza normalizzata per grado uscente

```{r}

A <- as_adjacency_matrix(graph, sparse = FALSE)

# Normalizzazione per riga (out-degree)
out_deg <- rowSums(A)
A_norm <- sweep(A, 1, out_deg, FUN = "/")

# Gestisci nodi con out-degree = 0 (righe diventano NaN)
A_norm[is.na(A_norm)] <- 0

cat("Dimensioni:", nrow(A_norm), "x", ncol(A_norm), "\n\n")

```

2. Calcolo del raggio spettrale

```{r}

eigenvalues <- eigen(A_norm)$values
rho_A <- max(Mod(eigenvalues))

cat("Raggio spettrale di A normalizzata:", round(rho_A, 6), "\n")
```
Il raggio spettrale 
ρ(A) è il valore assoluto massimo (modulo) degli autovalori di A.

Per una matrice stocastica (dove ogni riga somma a 1), come quella ottenuta normalizzando per grado uscente, il massimo autovalore è sempre 1.

Poiché ρ(A_norm)=1, il parametro α deve essere scelto strettamente inferiore a 1 per garantire la convergenza.


3. Scelta del parametro alpha

Cammini di lunghezza k contribuiscono con peso alpha^k

```{r}
# Usiamo 0.85 come nel PageRank
alpha <- 0.85 / rho_A

cat("Alpha scelto:", round(alpha, 6), "\n")
```

4. Calcolo della matrice di similarità globale

```{r}

n <- nrow(A_norm)
I <- diag(1, n)
M <- I - alpha * A_norm

# Inverto la matrice: S = (I - alpha*A)^(-1)
S_global <- solve(M)

rownames(S_global) <- V(graph)$name
colnames(S_global) <- V(graph)$name

```

5. Statistiche (esclusa diagonale)

Metto la diagonale principale a zero per evitare il fatto che si sballino i conti dato che un nodo è simile a se stesso.

```{r}

S_global_offdiag <- S_global
diag(S_global_offdiag) <- 0

cat("=== STATISTICHE GLOBAL SIMILARITY (esclusa diagonale) ===\n")
cat("  Min:", round(min(S_global_offdiag), 6), "\n")
cat("  Max:", round(max(S_global_offdiag), 6), "\n")
cat("  Media:", round(mean(S_global_offdiag), 6), "\n")
cat("  Mediana:", round(median(S_global_offdiag), 6), "\n\n")
```
Avere una similarità media molto bassa è tipico di reti sparse

6. Top 50 coppie per global similarity

```{r}

upper_tri_indices <- upper.tri(S_global_offdiag, diag = FALSE)

global_pairs <- data.frame(
  Paper1 = rownames(S_global_offdiag)[row(S_global_offdiag)[upper_tri_indices]],
  Paper2 = colnames(S_global_offdiag)[col(S_global_offdiag)[upper_tri_indices]],
  global_sim = S_global_offdiag[upper_tri_indices]
)

# Aggiungi le categorie dei paper
global_pairs <- global_pairs %>%
  mutate(
    Category1 = V(graph)$category[match(Paper1, V(graph)$name)],
    Category2 = V(graph)$category[match(Paper2, V(graph)$name)]
  )


top_global <- global_pairs %>%
  arrange(desc(global_sim)) %>%
  head(50)

kable(top_global,
      row.names = FALSE,
      digits = c(0, 0, 6),
      col.names = c("Paper 1", "Paper 2", "Global Similarity", "Categoria Paper1", "Categoria Paper2"))



```

E' interessante notare che vi sono anche coppie di nodi in cui i 2 paper appartengono a categorie diverse, come questa : 

95718	32698	3.063063	Theory	Probabilistic_Methods

7 Mostro la rete delle 500 coppie di nodi con più alto valore di Global similarity.

```{r fig.width=12, fig.height=9, fig.align='center', warning=FALSE}

top_200 <- global_pairs %>%
  arrange(desc(global_sim)) %>%
  head(200)

# Creo il grafo non diretto pesato sulle coppie top 200
graph_global <- graph_from_data_frame(top_200, directed = FALSE)

# Associo la categoria ai nodi
V(graph_global)$category <- V(graph)$category[match(V(graph_global)$name, V(graph)$name)]

# Palette colori 
categories <- unique(V(graph_global)$category)
palette_colors <- scales::hue_pal()(length(categories))  
names(palette_colors) <- categories

# Visualizziamo la rete 
ggraph(graph_global, layout = "fr") +
  geom_edge_link(aes(width = global_sim), color = "grey50", alpha = 0.7) +
  geom_node_point(aes(color = category), size = 3) +
  scale_edge_width(range = c(0.5, 4)) +  # Larghezza edge da min a max
  scale_color_manual(values = palette_colors) +
  theme_graph() +
  labs(
    title = "Network delle top 200 coppie per Global Similarity",
    color = "Categoria",
    width = "Global Similarity"
  )
```
  

##  2.4: Metriche a confronto

### Katz centrality e similarità

La Katz centrality di un nodo i è esattamente la somma delle similarità di i con tutti gli altri nodi.

```{r}

# Calcolo matrice di adiacenza normalizzata per grado uscente (se non già presente)
A <- as_adjacency_matrix(graph, sparse = FALSE)
out_deg <- rowSums(A)
A_norm <- sweep(A, 1, out_deg, FUN = "/")
A_norm[is.na(A_norm)] <- 0

# Calcolo raggio spettrale e impostazione alpha coerente
eig <- eigen(A_norm)$values
r <- max(abs(eig))
alpha <- 0.85 / r

# Calcola la Katz centrality in modo teoricamente correto
katz_manual <- as.vector(rowSums(S_global))  # Somma delle global similarity

# (opzionale) Aggiungi come nuovo attributo al grafo
V(graph)$katz_norm <- katz_manual

# Verifica numerica (devono essere uguali: la proprietà è soddisfatta)
cat("Differenza media Katz (somma S_global):", mean(abs(katz_manual - rowSums(S_global))), "\n")
cat("Differenza massima Katz (somma S_global):", max(abs(katz_manual - rowSums(S_global))), "\n")
cat("Correlazione Katz (somma S_global):", cor(katz_manual, rowSums(S_global)), "\n")

```
La relazione tra Katz e la somma delle similarità globali è dimostrata.

```{r}

# Dataframe confronto (ora le 2 colonne sono identiche per definizione!)
comparison_df <- data.frame(
  node = V(graph)$name,
  katz_manual = katz_manual,
  sum_sim = rowSums(S_global),
  difference = abs(katz_manual - rowSums(S_global))
)

# Statistiche confronto
cat("Correlazione Katz - Somma Global Similarity:", cor(comparison_df$katz_manual, comparison_df$sum_sim), "\n")
cat("Differenza media:", mean(comparison_df$difference), "\n")
cat("Differenza massima:", max(comparison_df$difference), "\n")

# Visualizza scatterplot aggiornato
ggplot(comparison_df, aes(x = katz_manual, y = sum_sim)) +
  geom_point(alpha = 0.85, color = "black") +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red", linewidth = 1) +
  labs(
    title = "Katz Centrality = Somma delle Similarità Globali",
    x = "Katz Centrality (manuale)",
    y = "Somma Global Similarity"
  ) +
  theme_minimal()



```

##  3 : Analisi di Eterogeneità

Un nodo è eterogeneo se è dissimile dai vicini.

L'eterogeneità può essere integrata nella centralità.
Infatti i nodi che ricevono archi da altri nodi che sono eterogenei, sono considerati più importanti rispetto a quelli che ricevono un arco da nodi molto simili tra loro.

Entrambe le misure che vedremo (Shannon e Simpson) sono massimizzate quando la probabilità è equamente distribuita tra gli elementi (pi = 1/n)

```{r}


```

##  3.1: Shannon Entropy

E' un modo di definire l'eterogeneità in modo parziale, non considerando la distanza.

In questo caso, la Shannon entropy misura quanto è eterogenea la distribuzione delle categorie tra i vicini di un paper (predecessori o successori).

Step 1: Crea una "distribuzione di probabilità" sui vicini

Per ogni nodo i:

  - Posso considerare i suoi predecessori (nodi che lo citano, in-neighbors) oppure successori (nodi che cita, out-neighbors)

  - Normalizzo per ottenere una distribuzione di probabilità, dove ai,j è 1 se esiste un arco da i a j, 0 altrimenti.
  
$$
p_{i,j} = \frac{a_{i,j}}{\sum_k a_{i,k}} = \frac{a_{i,j}}{d_i}
$$

La Shannon entropy misura quanto è eterogenea la distribuzione delle categorie tra i vicini di un nodo:


$$
H(i) = -\sum_{c \in \text{categorie}} p_{i,c} \log_2(p_{i,c})
$$
Per calcolarla, definiamo questa funzione

```{r}

# Funzione Shannon Entropy
shannon_entropy <- function(p) {
  # Rimuovi zeri per evitare log(0)
  p <- p[p > 0]
  if (length(p) == 0) return(0)
  -sum(p * log2(p))
}

```

Calcolo Shannon Entropy per ogni nodo (basato su predecessori).

Normalizziamo dunque per colonna (predecessori = in-neighbors).

Ogni colonna rappresenta la distribuzione dei predecessori per quel nodo.

Quindi per ogni nodo, calcola la distribuzione delle categorie dei predecessori.


```{r}

shannon_values <- sapply(V(graph), function(node) {
  # Ottieni predecessori (nodi che citano questo nodo)
  preds <- neighbors(graph, node, mode = "in")
  
  # Nessun predecessore = entropia 0
  if (length(preds) == 0) {
    return(0)  
  }
  
  # Categorie dei predecessori
  pred_categories <- V(graph)$category[preds]
  
  # Distribuzione di probabilità sulle categorie
  category_table <- table(pred_categories)
  p_categories <- as.numeric(category_table / sum(category_table))
  
  # Calcola Shannon Entropy
  shannon_entropy(p_categories)
})

# Aggiungi come attributo del grafo
V(graph)$shannon_entropy <- shannon_values

```

Creo ora il dataframe per fare un'analisi 

```{r}
# Crea dataframe per analisi
nodes_data <- data.frame(
  node = V(graph)$name,
  category = V(graph)$category,
  shannon = shannon_values
)

# Statistiche
cat("=== STATISTICHE SHANNON ENTROPY (predecessori) ===\n")
cat("Media:", round(mean(nodes_data$shannon, na.rm = TRUE), 4), "\n")
cat("Mediana:", round(median(nodes_data$shannon, na.rm = TRUE), 4), "\n")
cat("Min:", round(min(nodes_data$shannon, na.rm = TRUE), 4), "\n")
cat("Max:", round(max(nodes_data$shannon, na.rm = TRUE), 4), "\n\n")

```

La tabella mostra i 10 paper con la più alta Shannon Entropy, cioè quelli citati dal mix più diversificato di categorie.

```{r}

# Top 10 nodi più eterogenei
top_heterogeneous <- nodes_data %>%
  arrange(desc(shannon)) %>%
  head(10)

kable(top_heterogeneous, digits = 4,
      col.names = c("Paper", "Categoria", "Shannon Entropy"))

```
La Media: 0.2029 indica che in medi appunto i paper ricevono citazioni da un insieme abbastanza omogeneo di categorie


Entropia alta → nodo connesso a vicini di molte categorie diverse (eterogeneo)

Entropia bassa → nodo connesso a vicini della stessa categoria (omogeneo)



##  3.2: Simpson Diversity

Questa è un altro modo per valutare l'eterogeneità.

Misura la probabilità che due vicini scelti a caso appartengano a categorie diverse.

$$
S(i) = 1  - \sum_{c \in \text{categorie}} p_{i,c}^2
$$

```{r}

# Funzione Simpson Diversity
simpson_diversity <- function(p) {
  
  x = 1 - sum(p * p)
  return(x)
}

```

```{r}

# Per ogni nodo, calcola la distribuzione delle categorie dei predecessori
simpson_values <- sapply(V(graph), function(node) {
  # Ottieni predecessori (nodi che citano questo nodo)
  preds <- neighbors(graph, node, mode = "in")
  
  if (length(preds) == 0) {
    # Nessun predecessore = diversità 0
    return(0)  
  }
  
  # Categorie dei predecessori
  pred_categories <- V(graph)$category[preds]
  
  # Distribuzione di probabilità sulle categorie
  category_table <- table(pred_categories)
  p_categories <- as.numeric(category_table / sum(category_table))
  
  # Calcola Simpson Diversity
  simpson_diversity(p_categories)
})

```
    

```{r}

# Aggiungi come attributo del grafo
V(graph)$simpson_diversity <- simpson_values

# Crea dataframe per analisi
nodes_data <- data.frame(
  node = V(graph)$name,
  category = V(graph)$category,
  simpson = simpson_values
)

# Statistiche
cat("=== STATISTICHE SIMPSON DIVERSITY (predecessori) ===\n")
cat("Media:", round(mean(nodes_data$simpson, na.rm = TRUE), 4), "\n")
cat("Mediana:", round(median(nodes_data$simpson, na.rm = TRUE), 4), "\n")
cat("Min:", round(min(nodes_data$simpson, na.rm = TRUE), 4), "\n")
cat("Max:", round(max(nodes_data$simpson, na.rm = TRUE), 4), "\n\n")

```

Top 10 nodi più eterogenei (Simpson)

```{r}

top_heterogeneous <- nodes_data %>%
  arrange(desc(simpson)) %>%
  head(10)

kable(top_heterogeneous, digits = 4,
      col.names = c("Paper", "Categoria", "Simpson Diversity"))
```



##  3.3: Rao Quadratic Entropy

Differenza cruciale con Shannon e Simpson:

Shannon & Simpson: Misurano solo uniformità della distribuzione

Rao: Include anche quanto sono diverse le categorie tra loro!

L'interpretazione è che Rao è GRANDE quando:

  - La distribuzione è uniforme (distribuzione su molti elementi)

  - Gli elementi sono molto diversi tra loro (dissimilarità alta)


$$
R(i) = \sum_{c_1, c_2} p_{i,c_1} \cdot p_{i,c_2} \cdot d(c_1, c_2)
$$

dove 

  - pi,c è la proporzione dei vicini del nodo i nella categoria c

  - d(c1,c2) è la distanza/dissimilarità tra le categorie c1 e c2. 

Esempio: Una disciplina è molto eterogenea (interdisciplinare) se cita molte discipline diverse in proporzioni simili E quelle discipline sono dissimili tra loro.


Per un grafo diretto, hai due opzioni per definire i vicini di un nodo:

  - Out-neighbors (nodi citati): analizza l'eterogeneità delle categorie che il nodo i cita

  - In-neighbors (nodi citanti): analizza l'eterogeneità delle categorie che citano il nodo i

Nel contesto di un citation network, l'opzione più sensata è analizzare gli out-neighbors, perché misura quanto è interdisciplinare il pattern di citazioni in uscita.

Rao dunque misura quanto sono diverse tra loro le categorie che il paper i cita.



```{r}
# Prendo le informazioni dal grafo e le salvo
node_categories <- V(graph)$category
categories <- sort(unique(node_categories))
k <- length(categories)
n <- vcount(graph)

cat("============================================================================\n")
cat("RAO QUADRATIC ENTROPY - Setup\n")
cat("============================================================================\n")
cat("  Numero paper (nodi):", n, "\n")
cat("  Numero categorie:", k, "\n")
cat("  Categorie:", paste(categories, collapse = ", "), "\n\n")

```

STEP 1 : Creare una matrice di flusso F 

F è una (7×7) che rappresenta quante citazioni esistono tra categorie di paper. 

Qui abbiamo 7 categorie e 5429 citazioni totali tra di esse.


Per farlo ricorro all'uso della matrice indicatrice C, che vado a creare.

Essa è una matrice n × k (paper × categorie) dove ogni elemento vale:

  * C[i, c] = 1 se il paper i appartiene alla categoria c

  * C[i, c] = 0 altrimenti


Ottengo la matrice di Flusso F in questo modo : 

  * A × C : Prodotto tra matrice di adiacenza (n×n) e matrice indicatrice (n×k) → risultato (n×k)

    Per ogni paper i, conta quanti paper cita in ciascuna categoria

  * t(C) × (A × C) : Prodotto tra C trasposta (k×n) e il risultato precedente (n×k) → risultato (k×k)

    Aggrega per categoria di partenza

    F[c1, c2] = somma di tutte le citazioni da paper di categoria c1 a paper di categoria c2


```{r}
# Matrice Indicatrice C
C <- matrix(0, nrow = n, ncol = k)
colnames(C) <- categories

for (c_idx in 1:k) {
  C[, c_idx] <- as.numeric(node_categories == categories[c_idx])
}

# Matrice di flusso F
F <- t(C) %*% A %*% C

rownames(F) <- categories
colnames(F) <- categories

cat("  Matrice F calcolata:", nrow(F), "×", ncol(F), "\n")
cat("  Totale citazioni inter-categoria:", sum(F), "\n\n")

```
F rappresenta i "profili di citazione" delle categorie:

  - Ogni riga di F mostra quali categorie una determinata categoria tende a citare

  - Due categorie sono simili se hanno profili di citazione simili (citano le stesse altre categorie in proporzioni simili)



STEP 2 : Cosine Similarity tra CATEGORIE

Questo blocco calcola la cosine similarity tra tutte le coppie di categorie. 
La cosine similarity misura quanto sono simili due categorie in base ai loro "profili di citazione" (quali altre categorie tendono a citare).

La normalizzazione garantisce che la similarità dipenda solo dall'orientamento dei vettori (pattern di citazione), non dalla loro magnitudine (volume totale di citazioni).

```{r}

# Funzione per calcolare norma euclidea di un vettore
euclidean <- function(x) {sqrt(sum(x^2))}

# Calcola norme euclidee per ogni riga di F
norms <- apply(F, 1, euclidean)

# Matrice diagonale con 1/norma
D_norm <- diag(1 / norms)
# Per gestire le categorie senza citazioni
D_norm[!is.finite(D_norm)] <- 0  

# Cosine similarity: confronta profili di citazione tra categorie
S_cat <- D_norm %*% F %*% t(F) %*% D_norm

rownames(S_cat) <- categories
colnames(S_cat) <- categories

cat("  Similarità calcolata\n")
cat("  Range similarità:", round(min(S_cat), 3), "-", round(max(S_cat), 3), "\n\n")

```
  
STEP 3: Dissimilarità D tra CATEGORIE

```{r}

# Conversione della similarità in dissimilarità
D <- 1 - S_cat

# Simmetrizza (importante per Rao)
# D <- (D + t(D)) / 2

# Distanza da sé stessa = 0
diag(D) <- 0

cat("  Dissimilarità D calcolata\n")
cat("  Range dissimilarità:", round(min(D[D > 0]), 3), "-", round(max(D), 3), "\n")
cat("  Media dissimilarità:", round(mean(D[D > 0]), 3), "\n\n")

```
Dato che ottengo un valore alto per la Dissimilarità media : 0.911, significa che le categorie sono mediamente molto dissimili tra loro.

Questo è ottimo per la Rao Entropy perché significa che posso distinguere bene l'interdisciplinarità dato che le categorie son ben separate.


STEP 4: Distribuzione CATEGORIE per ogni PAPER

Creare la matrice P che contiene, per ogni paper, la distribuzione di probabilità delle categorie che cita.

Tale distribuzione P è essenziale nella formula di Rao (ha come dimensione : paper x categorie).

```{r}

# Creo una matrice n x 7 piena di 0
P <- matrix(0, nrow = n, ncol = k)
colnames(P) <- categories

# Faccio ora un loop sui papers, per ognuno vado a prendere i paper che esso cita
for (i in 1:n) {
  
  # Out-neighbors del paper i (paper citati da i)
  # which(A[i, ] > 0) restituisce gli indici dei paper citati, ossiadove c'è un 1 nella riga i di A
  out_neighbors <- which(A[i, ] > 0)
  
  if (length(out_neighbors) > 0) {
    
    # Estraggo tutte le categorie dei paper citati
    neighbor_cats <- node_categories[out_neighbors]
    
    # Calcola proporzioni per ogni categoria
    for (c in categories) {
      
      # Per ogni categoria, vedo infine P[i, c] che è : il numero di paper citati nella categoria c / totale paper citati
      P[i, c] <- sum(neighbor_cats == c) / length(out_neighbors)
    
      }
  }
}

papers_with_citations <- sum(rowSums(P) > 0)

cat("  Matrice P calcolata:", nrow(P), "×", ncol(P), "\n")
cat("  Paper con almeno 1 citazione out:", papers_with_citations, "\n\n")

```

STEP 5: Calcolo RAO per ogni PAPER
 
La funzione implementa la formula della Rao Quadratic Entropy in forma matriciale.

Ho che : 

  - p è il vettore di lunghezza k (7 nel tuo caso) con le proporzioni delle categorie per un singolo paper

  - D è la matrice k × k di dissimilarità tra categorie


La funzione diag(p) crea una matrice diagonale k × k con i valori di p sulla diagonale.



```{r}

# Funzione Rao 
rao <- function(p, D) {
  x <- diag(p) %*% D %*% diag(p)
  return(sum(c(x)))
}

# Applica la funzione Rao a ogni riga di P (ogni paper)
rao_values <- apply(P, 1, function(p_i) rao(p_i, D))

# Assegna nomi ai valori Rao
names(rao_values) <- V(graph)$name


```

Step 6 : Statistiche Specializzazione vs Interdisciplinarità
```{r}

cat("============================================================================\n")
cat("ANALISI SPECIALIZZAZIONE vs INTERDISCIPLINARITÀ\n")
cat("============================================================================\n\n")

# Calcola out-degree per ogni nodo
out_degrees <- degree(graph, mode = "out")

# Classificazione dei paper
terminali <- sum(out_degrees == 0)
interdisciplinari <- sum(rao_values > 0)
specializzati <- sum(out_degrees > 0 & rao_values == 0)

# Verifica totale
totale <- vcount(graph)
check_sum <- terminali + interdisciplinari + specializzati

cat("CLASSIFICAZIONE DEI PAPER:\n\n")

cat("1. Paper TERMINALI (non citano nessuno):\n")
cat("   Numero:", terminali, "\n")
cat("   Percentuale:", round(terminali / totale * 100, 2), "%\n")
cat("   → Nodi senza citazioni out\n\n")

cat("2. Paper SPECIALIZZATI (citano solo la propria categoria):\n")
cat("   Numero:", specializzati, "\n")
cat("   Percentuale:", round(specializzati / totale * 100, 2), "%\n")
cat("   → Out-degree > 0, ma Rao = 0\n")
cat("   → Citano solo paper della stessa categoria\n\n")

cat("3. Paper INTERDISCIPLINARI (citano categorie diverse):\n")
cat("   Numero:", interdisciplinari, "\n")
cat("   Percentuale:", round(interdisciplinari / totale * 100, 2), "%\n")
cat("   → Out-degree > 0 e Rao > 0\n")
cat("   → Citano paper di categorie diverse\n\n")

cat("----------------------------------------------------------------------------\n")
cat("TOTALE:\n")
cat("   Paper totali:", totale, "\n")
cat("   Somma classificazioni:", check_sum, "\n")
cat("   Verifica (devono coincidere):", ifelse(totale == check_sum, "✓ OK", "✗ ERRORE"), "\n\n")

# Statistiche aggiuntive
cat("============================================================================\n")
cat("STATISTICHE AGGIUNTIVE\n")
cat("============================================================================\n\n")

cat("Paper con citazioni out (specializzati + interdisciplinari):\n")
cat("   Numero:", specializzati + interdisciplinari, "\n")
cat("   Percentuale:", round((specializzati + interdisciplinari) / totale * 100, 2), "%\n\n")

# Statistiche Rao per paper interdisciplinari
rao_interdisciplinari <- rao_values[rao_values > 0]

cat("Statistiche Rao per paper INTERDISCIPLINARI (Rao > 0):\n")
cat("   Min:", round(min(rao_interdisciplinari), 4), "\n")
cat("   Max:", round(max(rao_interdisciplinari), 4), "\n")
cat("   Media:", round(mean(rao_interdisciplinari), 4), "\n")
cat("   Mediana:", round(median(rao_interdisciplinari), 4), "\n")
cat("   Deviazione standard:", round(sd(rao_interdisciplinari), 4), "\n\n")

# Distribuzione out-degree per tipo
cat("Out-degree medio per tipo:\n")
cat("   Paper specializzati:", round(mean(out_degrees[out_degrees > 0 & rao_values == 0]), 2), "\n")
cat("   Paper interdisciplinari:", round(mean(out_degrees[rao_values > 0]), 2), "\n\n")

cat("============================================================================\n")


```
Dunque sia i 1143 paper che non citano nessuno ed i 1265 paper che citano solo la propria categoria

Dunque su 1565 paper che almeno 1 citazione ad un altro paper, solo 300 citano più (paper) di una categoria 


Interpretazione dei valori : 

  - Rao = 0: Paper che non cita nessuno, oppure cita solo paper di una categoria

  - Rao basso (es. 0.1): Paper specializzato, cita principalmente categorie simili tra loro

  - Rao medio (es. 0.3-0.5): Paper moderatamente interdisciplinare

  - Rao alto (es. > 0.7): Paper fortemente interdisciplinare, cita molte categorie diverse e dissimili


STEP 7 : Aggiungo RAO come attributo del grafo

```{r}

V(graph)$rao_entropy <- rao_values

cat("  Attributo 'rao_entropy' aggiunto con successo\n\n")

```
STEP 8 : Top paper interdisciplinari

```{r}

# Ordina per Rao decrescente
top_rao_idx <- order(rao_values, decreasing = TRUE)[1:min(10, length(rao_values))]

top_rao_papers <- data.frame(
  paper = names(rao_values)[top_rao_idx],
  category = node_categories[top_rao_idx],
  rao_entropy = rao_values[top_rao_idx],
  out_degree = rowSums(A)[top_rao_idx],
  stringsAsFactors = FALSE
)

print(top_rao_papers, row.names = FALSE)

cat("\n")

```
  
STEP 9 :  

  * Top paper specializzati (Rao basso, ma con citazioni)
  * TOP paper poco Interdisciplinari (Rao > 0, ma basso)
  * Distribuzione per livello di interdisciplinarità

```{r}

# TOP 10 PAPER COMPLETAMENTE SPECIALIZZATI (Rao = 0)
# Citano solo paper della propria categoria

out_degrees <- degree(graph, mode = "out")
specialized_idx <- which(out_degrees > 0 & rao_values == 0)

if (length(specialized_idx) > 0) {
  
  # Ordina per out-degree decrescente (più citazioni = più specializzato)
  top_specialized_idx <- specialized_idx[order(out_degrees[specialized_idx], decreasing = TRUE)[1:min(10, length(specialized_idx))]]
  
  specialized_papers <- data.frame(
    paper = V(graph)$name[top_specialized_idx],
    category = node_categories[top_specialized_idx],
    rao_entropy = rao_values[top_specialized_idx],
    out_degree = out_degrees[top_specialized_idx],
    stringsAsFactors = FALSE
  )
  
  # STAMPA la tabella con print()
  print(kable(specialized_papers,
              row.names = FALSE,
              col.names = c("Paper", "Categoria", "Rao", "Out-degree")))
 
  
} else {
  cat("Nessun paper completamente specializzato trovato.\n\n")
}

# TOP 10 PAPER POCO INTERDISCIPLINARI (Rao > 0, ma basso)
# Citano principalmente una categoria, con poche eccezioni

# Filtra paper con Rao > 0
rao_with_cit <- rao_values[rao_values > 0]

if (length(rao_with_cit) > 0) {
  # Ordina per Rao crescente (valori più bassi = meno interdisciplinari)
  bottom_rao_idx <- order(rao_with_cit)[1:min(10, length(rao_with_cit))]
  
  bottom_rao_papers <- data.frame(
    paper = names(rao_with_cit)[bottom_rao_idx],
    category = node_categories[match(names(rao_with_cit)[bottom_rao_idx], names(rao_values))],
    rao_entropy = rao_with_cit[bottom_rao_idx],
    out_degree = out_degrees[match(names(rao_with_cit)[bottom_rao_idx], names(rao_values))],
    stringsAsFactors = FALSE
  )
  
  # STAMPA la tabella con print()
  print(kable(bottom_rao_papers,
              row.names = FALSE,
              digits = c(0, 0, 4, 0),
              col.names = c("Paper", "Categoria", "Rao", "Out-degree")))
  
} else {
  cat("Nessun paper con Rao > 0 trovato.\n\n")
}


# Confronto Statistico, distribuzione per livello di interdisciplinarità

# Crea categorie di interdisciplinarità
interdisciplinarity_levels <- data.frame(
  Livello = c("Terminali (nessuna citazione)",
              "Completamente specializzati (Rao = 0)",
              "Poco interdisciplinari (0 < Rao ≤ 0.3)",
              "Moderatamente interdisciplinari (0.3 < Rao ≤ 0.5)",
              "Altamente interdisciplinari (Rao > 0.5)"),
  Numero = c(
    sum(out_degrees == 0),
    sum(out_degrees > 0 & rao_values == 0),
    sum(rao_values > 0 & rao_values <= 0.3),
    sum(rao_values > 0.3 & rao_values <= 0.5),
    sum(rao_values > 0.5)
  ),
  stringsAsFactors = FALSE
)

interdisciplinarity_levels$Percentuale <- round(interdisciplinarity_levels$Numero / vcount(graph) * 100, 2)

print(kable(interdisciplinarity_levels,
            row.names = FALSE,
            col.names = c("Livello di Interdisciplinarità", "Numero Paper", "Percentuale (%)")))
```

    


##  4 : Confronto tra Similarità e Centralità

Domande di ricerca : 

  * I paper con alta centralità (es. PageRank, betweenness) tendono ad essere interdisciplinari?

  * I paper interdisciplinari sono più influenti nella rete?

  * C'è correlazione tra Rao entropy e le varie misure di centralità?
  
  
  
Domanda 1 : I paper con alta centralità (es. PageRank, betweenness) tendono ad essere interdisciplinari?

Procedimento : 

  - Identifico i paper più centrali (top 10% per PageRank e Betweenness)

  - Calcolo la distribuzione di Rao in questi paper centrali

  - Si confrontano con la distribuzione generale

  - Test statistico per verificare se c'è differenza significativa
   
```{r}

# Crea dataframe completo
df_analysis <- data.frame(
  paper = V(graph)$name,
  category = V(graph)$category,
  rao_entropy = rao_values,
  pagerank = V(graph)$pagerank,
  betweenness = V(graph)$betweenness,
  degree_out = degree(graph, mode = "out"),
  stringsAsFactors = FALSE
)

# Filtra solo paper con citazioni out (altrimenti Rao = 0 per definizione)
df_active <- df_analysis[df_analysis$degree_out > 0, ]

cat("Dataset per l'analisi:\n")
cat("  Paper totali:", nrow(df_analysis), "\n")
cat("  Paper con citazioni out:", nrow(df_active), "\n")
cat("  (Solo questi possono avere Rao > 0)\n\n")


# ============================================================================
# 1.1: Identificazione paper ad ALTA CENTRALITÀ
# ============================================================================

cat("----------------------------------------------------------------------------\n")
cat("1.1 - Identificazione paper ad ALTA CENTRALITÀ\n")
cat("----------------------------------------------------------------------------\n\n")

# Definisci threshold per "alta centralità" (top 10%)
threshold_pagerank <- quantile(df_active$pagerank, 0.90)
threshold_betweenness <- quantile(df_active$betweenness, 0.90)

# Classifica paper
df_active$high_pagerank <- df_active$pagerank >= threshold_pagerank
df_active$high_betweenness <- df_active$betweenness >= threshold_betweenness
df_active$high_centrality <- df_active$high_pagerank | df_active$high_betweenness

# Statistiche
n_high_centrality <- sum(df_active$high_centrality)
n_low_centrality <- sum(!df_active$high_centrality)

cat("Paper ad ALTA centralità (top 10% PageRank o Betweenness):", n_high_centrality, "\n")
cat("Paper a BASSA centralità:", n_low_centrality, "\n\n")

cat("Threshold utilizzati:\n")
cat("  PageRank >= ", format(threshold_pagerank, scientific = TRUE), "\n", sep = "")
cat("  Betweenness >= ", round(threshold_betweenness, 4), "\n\n", sep = "")


# ============================================================================
# 1.2: Distribuzione Rao nei paper ad ALTA vs BASSA centralità
# ============================================================================

cat("----------------------------------------------------------------------------\n")
cat("1.2 - Distribuzione Rao Entropy per livello di centralità\n")
cat("----------------------------------------------------------------------------\n\n")

# Separa i due gruppi
high_centrality_papers <- df_active[df_active$high_centrality, ]
low_centrality_papers <- df_active[!df_active$high_centrality, ]

# Statistiche descrittive per ALTA centralità
cat("Paper ad ALTA centralità (n =", nrow(high_centrality_papers), "):\n")
cat("  Rao medio:", round(mean(high_centrality_papers$rao_entropy), 4), "\n")
cat("  Rao mediano:", round(median(high_centrality_papers$rao_entropy), 4), "\n")
cat("  Rao max:", round(max(high_centrality_papers$rao_entropy), 4), "\n")
cat("  % con Rao > 0 (interdisciplinari):", 
    round(sum(high_centrality_papers$rao_entropy > 0) / nrow(high_centrality_papers) * 100, 2), "%\n\n")

# Statistiche descrittive per BASSA centralità
cat("Paper a BASSA centralità (n =", nrow(low_centrality_papers), "):\n")
cat("  Rao medio:", round(mean(low_centrality_papers$rao_entropy), 4), "\n")
cat("  Rao mediano:", round(median(low_centrality_papers$rao_entropy), 4), "\n")
cat("  Rao max:", round(max(low_centrality_papers$rao_entropy), 4), "\n")
cat("  % con Rao > 0 (interdisciplinari):", 
    round(sum(low_centrality_papers$rao_entropy > 0) / nrow(low_centrality_papers) * 100, 2), "%\n\n")


```
VISUALIZZAZIONE: Alta centralità → Maggiore interdisciplinarità

```{r}


# Prepara dati per il grafico (manualmente senza tidyr)
prop_data <- data.frame(
  Centralita = c("Alta", "Bassa"),
  Interdisciplinari = c(34.24, 15.67),
  Specializzati = c(65.76, 84.33)
)

# Reshape manuale (equivalente a pivot_longer)
prop_data_long <- data.frame(
  Centralita = rep(prop_data$Centralita, times = 2),
  Tipo = rep(c("Interdisciplinari", "Specializzati"), each = 2),
  Percentuale = c(prop_data$Interdisciplinari, prop_data$Specializzati)
)

# Crea barplot
p1 <- ggplot(prop_data_long, aes(x = Centralita, y = Percentuale, fill = Tipo)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.7) +
  geom_text(aes(label = paste0(round(Percentuale, 1), "%")),
            position = position_dodge(width = 0.7),
            vjust = -0.5, size = 4.5, fontface = "bold") +
  scale_fill_manual(values = c("Interdisciplinari" = "#06D6A0", 
                                "Specializzati" = "#EF476F")) +
  labs(title = "Paper Interdisciplinari per Livello di Centralità",
       subtitle = "I paper centrali hanno 2× più probabilità di essere interdisciplinari",
       x = "Livello di Centralità",
       y = "Percentuale (%)",
       fill = "Tipo di Paper") +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(face = "bold", size = 16),
        plot.subtitle = element_text(size = 12, color = "gray40"),
        legend.position = "top") +
  ylim(0, 100)

print(p1)


```



Domanda 2 : I paper interdisciplinari (alto Rao da out-degree) sono più influenti (alto in-degree/PageRank) ?

Definiamo questa "influenza" usando le metriche di centralità : PageRank, In-degree, Betweenness

Confronto l'influenza tra paper interdisciplinari (Rao > 0) vs specializzati (Rao = 0)


Stiamo misurando:

  - Input diversity (Rao da out-degree): quanto sono diversificato in ciò che cito

  - Output impact (Influenza da in-degree): quanto impatto ho sugli altri

Queste due dimensioni insieme danno un quadro completo della posizione di un paper nella rete.

Nota che  Katz e PageRank sono concettualmente simili, lasciamo fuori la Katz Ceantrality da questa analisi. 


Recap :

  - PageRank: "quanto sono importanti i miei citatori?"

  - In-degree: "quante citazioni ricevo?"

  - Betweenness: "quanto connetto parti diverse della rete?"
  
  

```{r fig.width=12, fig.height=9, fig.align='center', warning=FALSE}

# Grafico 1 : Betweeness

betw_data <- data.frame(
  Tipo = factor(c("Interdisciplinari", "Specializzati"), 
                levels = c("Specializzati", "Interdisciplinari")),
  Betweenness = c(inter_betweenness, spec_betweenness),
  Label = c(paste0(round(inter_betweenness, 1)), 
            paste0(round(spec_betweenness, 1)))
)

p1 <- ggplot(betw_data, aes(x = Tipo, y = Betweenness, fill = Tipo)) +
  geom_bar(stat = "identity", width = 0.6) +
  geom_text(aes(label = Label),
            vjust = -0.5, size = 7, fontface = "bold") +
  scale_fill_manual(values = c("Specializzati" = "#EF476F",
                                "Interdisciplinari" = "#06D6A0")) +
  labs(title = "Paper Interdisciplinari = PONTI tra Discipline",
       subtitle = "Betweenness 10× più alta → ruolo critico di connettore",
       x = "",
       y = "Betweenness Centrality (media)") +
  theme_minimal(base_size = 15) +
  theme(plot.title = element_text(face = "bold", size = 18, hjust = 0.5),
        plot.subtitle = element_text(size = 13, color = "gray40", hjust = 0.5),
        legend.position = "none",
        axis.text = element_text(size = 13, face = "bold")) +
  annotate("segment", 
           x = 1, xend = 2, 
           y = max(betw_data$Betweenness) * 0.7,
           yend = max(betw_data$Betweenness) * 0.7,
           arrow = arrow(ends = "both", length = unit(0.3, "cm")),
           color = "darkred", size = 1.2) +
  annotate("text", 
           x = 1.5, 
           y = max(betw_data$Betweenness) * 0.75,
           label = "10× più alta!", 
           size = 6, 
           fontface = "bold", 
           color = "darkred")

print(p1)


# Grafico 2: Comparison table-style

# Se gli specializzati hanno valore 100, quanto hanno gli interdisciplinari ?  
comparison_data <- data.frame(
  Metrica = rep(c("PageRank\n(Popolarità)", 
                  "In-degree\n(Citazioni)", 
                  "Betweenness\n(Ruolo ponte)"), each = 2),
  Tipo = rep(c("Specializzati", "Interdisciplinari"), times = 3),
  Valore_Norm = c(
    # PageRank (normalizzato al valore specializzati = 100)
    100, 72,
    # In-degree
    100, 95,
    # Betweenness
    100, 1119
  )
)

comparison_data$Tipo <- factor(comparison_data$Tipo, 
                                levels = c("Specializzati", "Interdisciplinari"))

p2 <- ggplot(comparison_data, aes(x = Metrica, y = Valore_Norm, fill = Tipo)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.7) +
  geom_hline(yintercept = 100, linetype = "dashed", color = "black", alpha = 0.5) +
  geom_text(aes(label = ifelse(Valore_Norm > 150, Valore_Norm, "")),
            position = position_dodge(width = 0.7),
            vjust = -0.5, size = 5, fontface = "bold") +
  scale_fill_manual(values = c("Specializzati" = "#EF476F",
                                "Interdisciplinari" = "#06D6A0")) +
  labs(title = "Confronto Multidimensionale: Interdisciplinari vs Specializzati",
       subtitle = "Valori normalizzati (Specializzati = 100)",
       x = "",
       y = "Valore Relativo (Specializzati = 100)",
       fill = "") +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(face = "bold", size = 16, hjust = 0.5),
        plot.subtitle = element_text(size = 12, color = "gray40", hjust = 0.5),
        legend.position = "top",
        axis.text.x = element_text(size = 11))

print(p2)



# Grafico 3: Focus solo sui paper interdisciplinari

# Evidenzia solo gli interdisciplinari
df_active$highlight <- df_active$tipo == "Interdisciplinare"

p_highlight <- ggplot(df_active, aes(x = pagerank * 10000, 
                                      y = betweenness)) +
  # Prima layer: specializzati in grigio
  geom_point(data = df_active[!df_active$highlight, ],
             color = "gray70", shape = 16, size = 3, alpha = 0.4) +
  
  # Secondo layer: interdisciplinari colorati
  geom_point(data = df_active[df_active$highlight, ],
             aes(color = category),
             shape = 15, size = 5, alpha = 0.9) +
  
  # CAMBIATO: Usa palette Set2
  scale_color_brewer(palette = "Set2",
                     name = "Categoria\n(Interdisciplinari)") +
  
  labs(title = "Paper Interdisciplinari: Ponti tra Discipline",
       subtitle = "■ Colorati = Interdisciplinari | ● Grigi = Specializzati (background)",
       x = "PageRank (×10000)",
       y = "Betweenness Centrality") +
  
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(face = "bold", size = 17, hjust = 0.5),
    plot.subtitle = element_text(size = 11, color = "gray40", hjust = 0.5),
    legend.position = "right",
    panel.grid.minor = element_blank()
  ) +
  
  guides(color = guide_legend(override.aes = list(size = 6)))

print(p_highlight)




# Grafico 4 : Facet per categoria 

# Se vuoi vedere ogni categoria separatamente
p_facet <- ggplot(df_active, aes(x = pagerank * 10000, 
                                  y = betweenness, 
                                  color = tipo,
                                  shape = tipo)) +
  geom_point(alpha = 0.7, size = 3) +
  
  scale_color_manual(values = c("Specializzato" = "#EF476F", 
                                 "Interdisciplinare" = "#06D6A0"),
                     name = "") +
  
  scale_shape_manual(values = c("Specializzato" = 16, "Interdisciplinare" = 4),
                     name = "") +
  
  facet_wrap(~ category, scales = "free", ncol = 3) +
  
  labs(title = "Paper Interdisciplinari per Categoria",
       subtitle = "✕ = Interdisciplinare | ● = Specializzato",
       x = "PageRank (×10000)",
       y = "Betweenness") +
  
  theme_minimal(base_size = 12) +
  theme(plot.title = element_text(face = "bold", size = 16),
        strip.text = element_text(face = "bold", size = 10),
        legend.position = "top")

print(p_facet)



```

I paper interdisciplinari (alto Rao da out-degree) sono più influenti (alto in-degree/PageRank) ?

  - Se intendiamo influenza come PageRank/In-degree allora no, infatti gli specializzati sono PIÙ citati (+28% PageRank).

  - Se intendiamo invece la Betweeness allora si, gli interdisciplinari hanno +1019% Betweenness.
    Sono i PONTI che connettono discipline diverse, hanno un ruolo CRITICO per la circolazione delle idee.
    


Domanda 3 : Quali categorie producono i paper più interdisciplinari? E quali beneficiano di più dai ponti interdisciplinari?

```{r fig.width=12, fig.height=9, fig.align='center', warning=FALSE}

# Interdisciplinarità per Categoria

# 3.1: Rao medio per categoria 

# Solo paper con citazioni out
df_active <- df_analysis[df_analysis$degree_out > 0, ]

# Aggrego per categoria
category_stats <- df_active %>%
  group_by(category) %>%
  summarise(
    n_papers = n(),
    rao_medio = mean(rao_entropy),
    perc_interdisciplinari = sum(rao_entropy > 0) / n() * 100,
    # Rao medio SOLO tra interdisciplinari
    rao_medio_inter = mean(rao_entropy[rao_entropy > 0]),
    betweenness_medio = mean(betweenness)
  ) %>%
  arrange(desc(rao_medio))

cat("Ranking categorie per interdisciplinarità:\n\n")
print(kable(category_stats,
            digits = c(0, 0, 4, 1, 4, 1),
            col.names = c("Categoria", "N Paper", "Rao Medio (tutti)", 
                         "% Interdisciplinari", "Rao Medio (inter)", "Betweenness Medio")))
cat("\n")

# Identifico tipi di categorie "ponte" vs "isola"
most_interdisciplinary <- category_stats$category[1]
least_interdisciplinary <- category_stats$category[nrow(category_stats)]

cat("Categoria più INTERDISCIPLINARE:", most_interdisciplinary, "\n")
cat("  - Rao medio:", round(category_stats$rao_medio[1], 3), "\n")
cat("  -", round(category_stats$perc_interdisciplinari[1], 1), "% dei paper sono interdisciplinari\n\n")

cat("Categoria più SPECIALIZZATA:", least_interdisciplinary, "\n")
cat("  - Rao medio:", round(category_stats$rao_medio[nrow(category_stats)], 3), "\n")
cat("  -", round(category_stats$perc_interdisciplinari[nrow(category_stats)], 1), "% dei paper sono interdisciplinari\n\n")


# ============================================================================
# 3.2: Visualizzazione - Barplot per categoria
# ============================================================================


# Barplot con % interdisciplinari
p_categories <- ggplot(category_stats, 
                       aes(x = reorder(category, perc_interdisciplinari), 
                           y = perc_interdisciplinari,
                           fill = perc_interdisciplinari)) +
  geom_bar(stat = "identity", width = 0.7) +
  geom_text(aes(label = paste0(round(perc_interdisciplinari, 1), "%")),
            hjust = -0.2, size = 4.5, fontface = "bold") +
  scale_fill_gradient(low = "#EF476F", high = "#06D6A0",
                      name = "% Interdisciplinari") +
  coord_flip() +
  labs(title = "Apertura Disciplinare: % Paper Interdisciplinari per Categoria",
       subtitle = "Alcune discipline integrano più conoscenza esterna di altre",
       x = "",
       y = "% Paper Interdisciplinari (Rao > 0)") +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(face = "bold", size = 16),
        plot.subtitle = element_text(size = 11, color = "gray40"),
        legend.position = "none") +
  ylim(0, max(category_stats$perc_interdisciplinari) * 1.15)

print(p_categories)
cat("\n")


# ============================================================================
# 3.3: SOLO citazioni CROSS-CATEGORIA (CORRETTO)
# ============================================================================

cat("3.3 - Pattern di Citazioni CROSS-Categoria\n")
cat("----------------------------------------------------------------------------\n\n")

# Filtra solo paper interdisciplinari
interdisciplinary_papers <- df_active[df_active$rao_entropy > 0, ]

cat("Analisi su", nrow(interdisciplinary_papers), "paper interdisciplinari\n\n")

# Per ogni paper interdisciplinare, guarda chi cita
cross_citations <- data.frame()

for (i in 1:nrow(interdisciplinary_papers)) {
  paper_idx <- which(V(graph)$name == interdisciplinary_papers$paper[i])
  cited_indices <- which(A[paper_idx, ] > 0)
  
  if (length(cited_indices) > 0) {
    source_cat <- interdisciplinary_papers$category[i]
    target_cats <- node_categories[cited_indices]
    
    # SOLO citazioni cross-category (from ≠ to)
    for (target_cat in unique(target_cats)) {
      if (source_cat != target_cat) {  # ← FILTRO AGGIUNTO
        n_cit <- sum(target_cats == target_cat)
        cross_citations <- rbind(cross_citations, 
                                 data.frame(from = source_cat,
                                           to = target_cat,
                                           weight = n_cit))
      }
    }
  }
}

# Aggrego
cross_summary <- cross_citations %>%
  group_by(from, to) %>%
  summarise(total_citations = sum(weight)) %>%
  arrange(desc(total_citations))

cat("Top 10 flussi di citazioni CROSS-categoria (from ≠ to):\n\n")
print(kable(head(cross_summary, 10),
            col.names = c("Da Categoria", "A Categoria", "N Citazioni")))
cat("\n")

# Statistiche aggregate
cat("Statistiche citazioni cross-categoria:\n")
cat("  Totale citazioni cross:", sum(cross_summary$total_citations), "\n")
cat("  Numero di coppie (from→to):", nrow(cross_summary), "\n")
cat("  Media citazioni per coppia:", round(mean(cross_summary$total_citations), 1), "\n\n")



# 3.4: Chi è il maggior ESPORTATORE vs IMPORTATORE?


cat("3.4 - Ruolo delle Categorie nel Network\n")
cat("----------------------------------------------------------------------------\n\n")

# Calcola out-flow (quanto esporta) e in-flow (quanto importa)
export_summary <- cross_summary %>%
  group_by(from) %>%
  summarise(citazioni_out = sum(total_citations)) %>%
  rename(category = from)

import_summary <- cross_summary %>%
  group_by(to) %>%
  summarise(citazioni_in = sum(total_citations)) %>%
  rename(category = to)

trade_balance <- merge(export_summary, import_summary, by = "category", all = TRUE)
trade_balance[is.na(trade_balance)] <- 0
trade_balance$balance <- trade_balance$citazioni_out - trade_balance$citazioni_in
trade_balance <- trade_balance %>% arrange(desc(balance))

print(kable(trade_balance,
            col.names = c("Categoria", "Esporta (cita out)", "Importa (citata da)", "Bilancia"),
            digits = 0))

cat("Interpretazione:\n")
cat("  - balance POSITIVO: categoria 'esporta' più idee verso altre discipline\n")
cat("  - balance NEGATIVO: categoria 'importa' più idee da altre discipline\n\n")


# ============================================================================
# 3.5: CONCLUSIONE
# ============================================================================


most_open <- category_stats$category[1]
most_closed <- category_stats$category[nrow(category_stats)]
top_bridge <- cross_summary$from[1]


cat("1. APERTURA DISCIPLINARE:\n")
cat("   - Più aperta:", most_open, 
    "(", round(category_stats$perc_interdisciplinari[1], 1), "% interdisciplinari )\n")
cat("   - Più chiusa:", most_closed,
    "(", round(category_stats$perc_interdisciplinari[nrow(category_stats)], 1), "% interdisciplinari )\n\n")

cat("2. FLUSSI INTERDISCIPLINARI:\n")
cat("   - Flusso principale:", cross_summary$from[1], "→", cross_summary$to[1],
    "(", cross_summary$total_citations[1], "citazioni cross )\n")
cat("   - Totale citazioni cross-disciplinari:", sum(cross_summary$total_citations), "\n\n")

cat("3. RUOLI NEL NETWORK:\n")
cat("   - Maggior esportatore:", trade_balance$category[1],
    "(balance +", trade_balance$balance[1], ")\n")
cat("   - Maggior importatore:", trade_balance$category[nrow(trade_balance)],
    "(balance", trade_balance$balance[nrow(trade_balance)], ")\n\n")


```

- Ne concludo che la categoria :
    
  - Più aperta è la Theory ( 30.9 % interdisciplinari )
  
  - Più chiusa è la Genetic_Algorithms ( 10.6 % interdisciplinari )

- Flusso principale: Theory → Neural_Networks ( 82 citazioni  )

   - Totale citazioni cross-disciplinari: 874 

- Maggior esportatore in proporzione 

   - quella che Cita maggiormente in proporzione : Theory (bilancia + 72 )
   - quella che viene Citata maggiormente in proporzione : Case_Based (bilancia -43 )


Le discipline non sono ugualmente 'aperte'. Alcune (come Theory) integrano attivamente conoscenza da altri campi.
Altre invece (come Genetic_Algorithms) rimangono più isolate. 

Questo riflette differenze epistemiche e metodologiche.

```{r}


```

```{r}


```
