---
title: "02_Centrality_Analysis"
author: "Edoardo Diana"
date: "2025-11-15"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Indice 

   1 : Caricare le librerie e dati da usare
   2 : Calcolo delle le metriche di centralità
      
      * 2.1 : Degree centrality
          - In-degree
          - Out-degree
      * 2.2 : Closness Centrality
      * 2.3 : Betweenness Centrality
      * 2.4 : Eigenvector Centrality
      * 2.5 : Page Rank Centrality
      * 2.6 : HITS
      * 2.7 : Katz Centrality
      
   3 : Paragoni tra le centralità
   4 : Power 
   5 : Compare Power and Katz Centrality
   
   6 : Domanda 1 : Trova le 30 coppie (i, j) con più paper citati in comune (common successors)

       Domanda 2 : Trova le 30 coppie con più paper citanti in comune (common predecessors)

   7 : Domanda 3 : identify powerful categorie that are not central and central categories che non so powerful.
   
   8 : Domanda 4 : plot the network tra categorie with node size proportional to power and centrality and edge width proportional to citation flow
   
   9 : Salvataggio Metriche computate


##  1 : Caricare le librerie e dati da usare

```{r}
library(igraph)
library(dplyr)
library(tidygraph)
library(ggrepel)
library(ggplot2)
library(ggraph)
library(Matrix)
library(corrplot)
library(tidyr)
```

Caricamento dati dal notebook precedente

```{r}

dir_processed <- "../data/processed"

graph <- readRDS(file.path(dir_processed, "graph.rds"))
content_nodes <- readRDS(file.path(dir_processed, "content_nodes.rds"))
edge_table_named <- readRDS(file.path(dir_processed, "edges.rds"))

cat("Oggetti caricati correttamente\n")

```

## 2 : Calcolo di tutte le metriche di centralità

  * Degre Centrality :
      - In-degree Centrality
      - Out-degree Centrality
  * Closness Centrality
  * Betweenness Centrality
  * Eigenvector Centrality
  * Page Rank Centrality
  * HITS
  * Katz Centrality

```{r}

graph <- graph %>%
  activate(nodes) %>%
  mutate(
    indegree = centrality_degree(mode = "in"),
    outdegree = centrality_degree(mode = "out"),
    pagerank = centrality_pagerank(),
    closeness = centrality_closeness(),
    betweenness = centrality_betweenness()
  )
```

## 2.1 Degree centrality

Il degree (grado) è il numero di archi incidenti ad un nodo.

Un nodo è importante se è linkato da tanti altri nodi. 

Qui lavoriamo con un grafo diretto, dunque ne avrò 2 tipi di degree : 

  - In-degree: numero di archi entranti (citazioni ricevute da un paper)

  - Out-degree: numero di archi uscenti (citazioni fatte da un paper)


Prendo i top 500 nodi più centrali considerando solo in-degree

```{r}

top_ids <- graph %>%
  as_tibble() %>%
  top_n(500, indegree) %>%
  pull(name)

subgraph_top <- graph %>%
  activate(nodes) %>%
  filter(name %in% top_ids)

```

Visualizzazione della rete considerando In-degree

```{r fig.width=12, fig.height=9, fig.align='center', warning=FALSE}

set.seed(42)

ggraph(subgraph_top, layout = "fr") +
  geom_edge_link(alpha = 0.2, edge_colour = "gray60") +
  geom_node_point(aes(color = category, size = indegree), alpha = 0.85) +
  scale_color_brewer(palette = "Set2") +
  labs(
    title = "Sottorete dei 500 paper più centrali",
    subtitle = "Centralità = in-degree + out-degree",
    size = "In-Degree Centrality",
    color = "Category"
  ) +
  theme_void() +
  theme(legend.position = "right")

graph %>%
  activate(nodes) %>%
  as_tibble() %>%
  ggplot(aes(x = indegree, fill = category)) +
  geom_histogram(binwidth = 1, position = "stack", color = "black", alpha = 0.75) +
  scale_fill_brewer(palette = "Set2") +
  labs(
    title = "Distribuzione dell'In-degree Centrality per Categoria",
    x = "In-degree centrality",
    y = "Numero di paper",
    fill = "Categoria"
  ) +
  theme_minimal()

```

## 2.2 : Closeness centrality

La closeness indica quanto un nodo si trova “vicino” a tutti gli altri, cioè l’inverso della distanza media (numero di passi minimi) dagli altri nodi raggiungibili.

Un paper con closeness alta è raggiungibile facilmente dagli altri e potenzialmente è un “crocevia” di informazioni.

Ho però che la mia rete è "non fortemente connessa”, infatti la struttura delle citazioni è molto asimmetrica e “sparsa”.

In questi casi la closeness perde di informatività.
 
Infatti è molto informativa solo per reti fortemente connesse, mentre in reti grandi e dirette ho che molte distanze sono infinite.

La presenza di numerosi nodi isolati e la frammentazione della rete rendono la closeness centrality poco informativa, poiché questa metrica assume che tutti i nodi possano raggiungere tutti gli altri nodi, condizione non verificata in questa rete.


Elenco i top 10 paper per Closeness

```{r}

top_closeness <- graph %>%
  as_tibble() %>%
  arrange(desc(closeness)) %>%
  select(name, closeness, category) %>%
  head(10)

print(top_closeness)


# Estraggo solo i nomi dei nodi con closeness più alta
top_ids_closeness <- graph %>%
  as_tibble() %>%
  top_n(10, closeness) %>%
  pull(name)

# Creo la sottorete sui nodi con closeness più alta
subgraph_closeness <- graph %>%
  activate(nodes) %>%
  filter(name %in% top_ids_closeness)

```



## 2.3 : Betweenness centrality

La betweenness misura quante volte un nodo appare nei cammini minimi tra altri nodi. Rileva i “ponti” critici della rete.

Elenco i top 10 paper per Betweenness

High betweenness = ruolo di ponte/intermediazione.

Rimuovere nodi con alta betweenness casua la più grande distruzione delle comunicazioni tra gli altri vertici.


Prendo i Top 10 paper per Betweenness, mostro la tabella ed il grafo a barre. 

Infine la distribuzione dei paper in merito alla Betweenness.

```{r}
top_betw <- graph %>%
  as_tibble() %>%
  arrange(desc(betweenness)) %>%
  select(name, betweenness, category) %>%
  head(10)

print(top_betw)


ggplot(top_betw, aes(x = reorder(name, betweenness), y = betweenness, fill = category)) +
  geom_col() +
  coord_flip() +
  labs(
    title = "Top 10 paper per Betweenness",
    x = "Paper ID",
    y = "Betweenness"
  )

```

Distribuzione della Betweenness centrality e Distribuzione della Betweenness centrality per categoria

```{r}

# Distribuzione della Betweenness centrality

graph %>%
  as_tibble() %>%
  ggplot(aes(betweenness)) +
  geom_histogram(bins = 60, fill = "steelblue", color = "gray20", alpha = 0.75) +
  labs(
    title = "Distribuzione della Betweenness centrality",
    x = "Betweenness",
    y = "Numero di paper"
  )


# Distribuzione Betweenness per categoria

graph %>%
  as_tibble() %>%
  ggplot(aes(x = category, y = betweenness, fill = category)) +
  geom_boxplot(show.legend = FALSE, outlier.size=0.5) +
  labs(
    title = "Distribuzione Betweenness per categoria",
    x = "Categoria",
    y = "Betweenness"
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

## 2.4 Eigenvector Centrality

E' una estnsione della degre centrality, la quale assgnava 1 punto per ogni link entrante che un nodo riceve.

Ora un nodo è importante se è linkato da altri nodi importanti.

Un problema pratico dell'eigenvector centrality è che funziona bene solo se il grafo è (fortemente) connesso.

Le reti dirette reali, come quella che stiamo considerando qui, non hanno tali caratteristiche.

Se una rete diretta non è fortemente connessa, allora solo i vertici che si trovano in componenti fortemente connesse di almeno due nodi, o nella componente uscente (out-component) di tali componenti, possono avere eigenvector centrality non nulla.

Dunque non procedo con l'esplorare questa metrica.

## 2.5 Page Rank

Un nodo è importante se è linked da altri nodi importanti e cita altri nodi in modo parsimonioso o se riceve molti archi entranti.

Ho che 3 fattori distinti determinano il PageRank di un nodo : 

  - il numero di link che riceve 
  - la centralità dei nodi da cui riceve i link
  - quanto i nodi da cui si ricevono i link sono propensi a linkar altri nodi

Prendo i top 10 paper per Page Rank

```{r}

top_pagerank <- graph %>%
  as_tibble() %>%
  arrange(desc(pagerank)) %>%
  select(name, category, pagerank, indegree, outdegree) %>%
  head(10)

print(top_pagerank)

```

Amplio poi l'analisi per capire cosa influenza maggiormente il PageRank dei top paper.

```{r fig.width=12, fig.height=9, fig.align='center', warning=FALSE}

# Ottieni i nodi con indice e attributi
nodes_data <- graph %>%
  activate(nodes) %>%
  as_tibble() %>%
  mutate(node_idx = row_number())

# Calcola statistiche dei predecessori (chi cita) per ogni nodo
predecessor_stats <- graph %>%
  activate(edges) %>%
  as_tibble() %>%
  # Join con nodes_data per ottenere PageRank e outdegree dei "from" (chi cita)
  left_join(
    nodes_data %>% select(from = node_idx, pr_citing = pagerank, out_citing = outdegree),
    by = "from"
  ) %>%
  # Raggruppa per "to" (chi viene citato) e calcola medie E massimo
  group_by(to) %>%
  summarise(
    avg_pr_citing = mean(pr_citing, na.rm = TRUE),
    max_pr_citing = max(pr_citing, na.rm = TRUE),  # NUOVO: max PageRank
    avg_outdegree_citing = mean(out_citing, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  # Converti "to" da indice a nome
  left_join(nodes_data %>% select(to = node_idx, name), by = "to") %>%
  select(name, avg_pr_citing, max_pr_citing, avg_outdegree_citing)

# Aggiungi queste statistiche ai top paper
top_pagerank_complete <- top_pagerank %>%
  left_join(predecessor_stats, by = "name")

print(top_pagerank_complete)


```


Stampo un grafico a barre che mostra le stesse informazioni.
Poi mostro la distribuzione Globale del PageRank.

```{r}

ggplot(top_pagerank, aes(x = reorder(name, pagerank), y = pagerank, fill = category)) +
  geom_col() +
  coord_flip() +
  labs(
    title = "Top 10 paper per PageRank",
    x = "Paper ID",
    y = "PageRank",
    fill = "Categoria ML"
  ) +
  scale_fill_brewer(palette = "Set2")

# Distribuzione Globale del PageRank
graph %>%
  as_tibble() %>%
  ggplot(aes(pagerank)) +
  geom_histogram(bins = 60, fill = "steelblue", color = "gray20", alpha = 0.75) +
  labs(
    title = "Distribuzione del PageRank",
    x = "PageRank",
    y = "Numero di paper"
  )

```
## 2.6 : HITS

Qui si valuta l'importanza di un nodo anche in base a quanto sono importanti i noti citati dal nodo analizzato (Hub)

Qui abbiamo 2 tipi di nodi centrali : 

  - Autorità : contengono informazioni importanti riguardo il topic di interesse

  - Hub : mi dice dov trovare le informazioni autorevoli
  
Un nodo può anche essr entrambi o nessuno


La Kleinberg centrality thesis dice : 

Un nodo è un' Autorità se è linkato da Hubs, è un Hub se linka delle Autorità.


```{r fig.width=12, fig.height=9, fig.align='center', warning=FALSE}

# Calcolo di HITS (Hub e Authority scores)
hits_result <- authority_score(graph, scale = TRUE)
hub_result <- hub_score(graph, scale = TRUE)

# Aggiungo entrambi ai nodi del grafo
graph <- graph %>%
  mutate(
    authority = hits_result$vector,
    hub = hub_result$vector
  )

```

Top 10 Authorities (paper autorevoli)

```{r}

top_authority <- graph %>%
  as_tibble() %>%
  arrange(desc(authority)) %>%
  select(name, authority, category) %>%
  head(10)

print(top_authority)

```

Top 10 Hub (paper che linkano autorità)

```{r}

top_hub <- graph %>%
  as_tibble() %>%
  arrange(desc(hub)) %>%
  select(name, hub, category) %>%
  head(10)

print(top_hub)


```

Vediamo come sono distribuiti i vari paper

```{r fig.width=12, fig.height=9, fig.align='center', warning=FALSE}

graph %>%
  as_tibble() %>%
  ggplot(aes(x = authority, y = hub, color = category)) +
  geom_point(alpha = 0.6, size = 2) +
  scale_color_brewer(palette = "Set2") +
  labs(
    title = "Relazione tra Authority e Hub score (HITS)",
    x = "Authority score",
    y = "Hub score",
    color = "Categoria ML"
  ) +
  theme_minimal()


```

Da analisi precedenti sappiamo che ogni paper riceve al massimo 5 citazioni in totale. 

Ciò si traduce nel fatto che un paper per essere un hub, ha solo 5 link a disposizione al massimo e deve cercare di linkare più authorities possibili.   


Network dei top 100 paper per authority score.

Vediamo tale rete prima in base all'Authority Score, e poi mantenendo edges e nodi ne mostriamo anche il relativo Hub Score.

```{r fig.width=12, fig.height=9, fig.align='center', warning=FALSE}

# Estraggo i nomi dei top 100 paper per authority
top100_authority_ids <- graph %>%
  activate(nodes) %>%
  as_tibble() %>%
  arrange(desc(authority)) %>%
  head(100) %>%
  pull(name)

# Creo il subgrafo indotto da questi 100 nodi
igraph_sub <- induced_subgraph(graph, vids = which(V(graph)$name %in% top100_authority_ids))

coords <- layout_with_fr(igraph_sub)

palette_categoria <- RColorBrewer::brewer.pal(length(unique(V(igraph_sub)$category)), "Set3")
colori_nodi <- palette_categoria[as.numeric(as.factor(V(igraph_sub)$category))]


# Plot Authority
plot(
  igraph_sub,
  layout = coords,
  vertex.size = 8 + 12 * (V(igraph_sub)$authority - min(V(igraph_sub)$authority)) / max(V(igraph_sub)$authority),
  vertex.color = colori_nodi,
  vertex.label = round(V(igraph_sub)$authority, 2),
  vertex.label.cex = 0.8,
  edge.arrow.size = 0.5,
  main = "Top 100 paper per Authority"
)

# Legenda 
legend(
  "topright",
  legend = levels(as.factor(V(igraph_sub)$category)),
  col = palette_categoria,
  pch = 19,
  pt.cex = 1.5,
  bty = "n",
  title = "Categoria"
)


# Plot Hub con
plot(
  igraph_sub,
  layout = coords,
  vertex.size = 5 + 15 * (V(igraph_sub)$hub - min(V(igraph_sub)$hub)) / max(V(igraph_sub)$hub),
  vertex.color = colori_nodi,
  vertex.label = round(V(igraph_sub)$hub, 2),
  vertex.label.cex = 0.8,
  edge.arrow.size = 0.5,
  main = "Hub score (HITS) dei Top 100 paper per Authority"
)

legend(
  "topright",
  legend = levels(as.factor(V(igraph_sub)$category)),
  col = palette_categoria,
  pch = 19,
  pt.cex = 1.5,
  bty = "n",
  title = "Categoria"
)

```



## 2.7 : Katz centrality

Questa metrica supera i problemi della Eigenvector Centrality nel nostro contsto.

L'idea è di dare ad ogni nodo uno small amount di centrality in modo gratuito.

Dunque : 

Un nodo è importante se se è linkato da nodi importanti o se riceve tanti archi entranti.

Quindi un paper ha alta Katz se riceve citazioni da paper che a loro volta ricevono molte citazioni. 


Nel codice subito sotto : 

  - Calcolare il raggio spettrale r (massimo autovalore in valore assoluto)

  - Usare alpha = 0.85/r (damping factor) per garantire convergenza (serve alpha < 1/r)

  - Calcolare la Katz Centrality mediante la funzione alpha_centrality(), che implementa la formula di Katz

```{r}

A <- as_adjacency_matrix(graph, sparse = TRUE)
eig <- eigen(A)$values
r = max(abs(eig))
alpha <- 0.85 / r
katz <- alpha_centrality(graph, alpha = alpha)

# Aggiungo come attributo dei nodi la Katz calcolata
graph <- graph %>%
  mutate(katz = katz)

graph
```

Il problema della Katz Centrality è che:

Se un nodo con alta centralità è connesso a tanti altri nodi -> tutti questi altri nodi linkati acquisiscono alta Centralità.

La centralità guadagnata in virtù del ricevere un link da un nodo importante dovrebbe esser diluita se il nodo importante è molto proponso a linkare altri nodi.

Il PageRank risolve questo problema. 

## 3 : Paragoni tra le centralità

```{r}

# Estraggo i nodi come dataframe
nodes <- graph %>% activate(nodes) %>% as_tibble()

# Computo la media per ciascuna metrica e categoria
compare <- nodes %>%
  group_by(category) %>%
  summarise(
    avg_indegree = mean(indegree, na.rm = TRUE),
    avg_outdegree = mean(outdegree, na.rm = TRUE),
    avg_pagerank = mean(pagerank, na.rm = TRUE),
    avg_closeness = mean(closeness, na.rm = TRUE),
    avg_betweenness = mean(betweenness, na.rm = TRUE),
    avg_katz = mean(katz, na.rm = TRUE),
    # Numero di paper in quella categoria
    n = n()
  ) %>%
  # Ordina per vedere una metrica in particolare
  arrange(desc(avg_pagerank)) 

compare

```

Questo plot riassume e comunica quali categorie sono più centrali, intermediarie o ben collegate nella rete secondo le diverse misure.

```{r fig.width=12, fig.height=9, fig.align='center', warning=FALSE}

# Ristruttura i dati in formato long per ggplot
compare_long <- compare %>%
  select(-n) %>%
  pivot_longer(-category, names_to = "metric", values_to = "mean_value") %>%
  mutate(metric = factor(metric,
                         levels = c("avg_indegree", "avg_outdegree", "avg_pagerank", "avg_closeness", "avg_betweenness", "avg_katz"),
                         labels = c("Indegree", "Outdegree", "PageRank", "Closeness", "Betweenness", "Katz")))


# Grafico a barre con faceting per metrica
ggplot(compare_long, aes(x = category, y = mean_value, fill = category)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ metric, scales = "free_y", ncol = 2) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Medie delle metriche di centralità per Categoria",
       x = "Categoria",
       y = "Media")
```

Vediamo ora la correlazione tra le varie misure di Centralità.

```{r}

M <- compare %>% 
  select(avg_indegree, avg_outdegree, avg_pagerank, avg_closeness, avg_betweenness, avg_katz) %>%
  as.matrix()

# Calcolo la matrice delle correlazioni
corM <- cor(M, use = "complete.obs")

print(corM)

corrplot(corM, method = "color", addCoef.col = "black", tl.col = "black", number.cex=0.7)

```


Le metriche di grado e Katz formano un cluster di misure fortemente correlate che riflettono l’attività immediata e l’influenza cumulativa nei network. 

Pagerank e Closeness invece evidenziano aspetti più distinti della centralità, spesso inversamente correlati, rivelando diverse modalità di importanza nel network.



## 4 : Power

In alcune circostanze la Centralità ha un'utilità limitata nel predirre chi detiene il potere nelle reti.

Un nodo è MOLTO potente se è connesso con nodi POCO potenti.


La funzione sotto riportata implementa l'algoritmo iterativo di Bonacich Power Centrality.

La formula iterata è: x_(k+1) = (1 - x_k) · A

Il damping factor (0.15) serve per stabilità numerica.

Converge quando la differenza tra iterazioni consecutive è < 10^(-6)


Vediamo qui la funzion per calcolare la power.

Modifiche per evitare l'errore "Diff is NA":

  - Ad ogni iterazione verifica che (1 - x_2) %*% A non produca NA/NaN/Inf, altrimenti interrompe il ciclo con un errore esplicito.

  - Normalizzazione: Divide x_2 per max(abs(x_2)) ad ogni passo per evitare overflow/underflow numerico che causerebbero valori NA.

  - Aggiunto max_iter = 1000 per prevenire loop infiniti e conversione da matrice sparse a densa per evitare comportamenti inaspettati.
  
```{r}

power <- function(A, t) {
  n <- dim(A)[1]
  x_0 <- rep(0, n)
  x_1 <- rep(1, n)
  x_2 <- rep(1, n)
  diff <- 1
  eps <- 1 / 10^t
  iter <- 0
  max_iter <- 1000
  
  while (!is.na(diff) && diff > eps && iter < max_iter) {
    x_0 <- x_1
    x_1 <- x_2
    
    temp <- (1 - x_2) %*% A
    
    # Controllo valori invalidi
    if (any(is.na(temp)) || any(is.nan(temp)) || any(is.infinite(temp))) {
      stop("Valori non numerici (NA/NaN/Inf) rilevati durante l'iterazione power centrality")
    }
    
    x_2 <- as.vector(temp)
    
    # Normalizzazione vettore
    max_abs <- max(abs(x_2))
    if (max_abs > 0) {
      x_2 <- x_2 / max_abs
    }
    
    diff <- sum(abs(x_2 - x_0))
    iter <- iter + 1
  }
  
  if (is.na(diff)) stop("Diff is NA durante l'iterazione")
  return(list(vector = as.vector(x_2), iter = iter))
}

```

Calcolo effettivo della Power centrality

```{r}

# Conversione matrice sparsa in densa
A_dense <- as.matrix(A)

damping <- 0.15
n <- nrow(A_dense)
I <- diag(damping, n)
Ad <- A_dense + I

# Calcolo Power centrality
p <- power(Ad, 6)$vector

# Aggiunta al grafo
graph <- graph %>%
  mutate(power = p)

graph
```


## 5 : Paragone tra Power and Katz Centrality

Alta Katz = Paper molto citato da altri paper autorevoli (è un "riferimento" nella comunità)

Alta Power = Paper che può influenzare altri paper 

```{r}

cat("Top-5 states by katz centrality : \n\n")
# sort top-5 states according to katz centrality

round(sort(katz, decreasing=TRUE)[1:5], 3)


cat("Top-5 states by Power : \n\n")
# sort top-5 states according to power

round(sort(p, decreasing=TRUE)[1:5], 2)

# correlation
cat("Correlazione di Kendall tra Katz e Power : ")
cor(katz, p, method="kendall")

```

La correlazione di Kendall tra Katz e Power è circa 0.56, indicando una correlazione moderata: i due indici sono legati ma misurano aspetti leggermente diversi della centralità.

```{r fig.width=12, fig.height=9, fig.align='center', warning=FALSE}

nodes <- graph %>% activate(nodes) %>% as_tibble()

# Calcola i quantili 75% per Katz e Power:

q_katz <- quantile(nodes$katz, 0.75)
q_power <- quantile(nodes$power, 0.75)

# Visualizza con ggplot2 la relazione tra Katz e Power, aggiungendo linee ai quantili e le etichette:

top_nodes <- nodes %>% filter(katz > q_katz | power > q_power)

ggplot(nodes, aes(x = katz, y = power, color = category)) +
  geom_point(alpha = 0.5, size = 2) +
  geom_label_repel(data = top_nodes, aes(label = name), 
                   max.overlaps = 15, size = 3) +
  geom_hline(yintercept = q_power, linetype = "dashed", alpha = 0.5) +
  geom_vline(xintercept = q_katz, linetype = "dashed", alpha = 0.5) +
  scale_color_brewer(palette = "Set2") +
  labs(title = "Confronto Katz e Power Centrality per Categoria",
       x = "Katz Centrality", y = "Power Centrality",
       color = "Categoria") +
  theme_minimal()

```


## 6 : Uso delle 2 matrici proiezioni A %*% t(A) e t(A) %*% A (prodotto matriciale)

  - Trova le 30 coppie (i, j) con più paper citati in comune (common successors)

  - Trova le 30 coppie con più paper citanti in comune (common predecessors)

Voglio studiare ora quanti paper citanti hanno in comune 2 paper i e j, e quanti paper citanti hanno in comune 2 paper i e j

```{r fig.width=12, fig.height=9, fig.align='center', warning=FALSE}
# Richiesta la libreria MAtrix 

# Matrice di adiacenza (sparse)
A <- as_adj(graph, sparse = TRUE)

# Matrice dei paper citati in comune (successori comuni)
common_cited <- as.matrix(A %*% t(A))
diag(common_cited) <- 0

# Matrice dei paper citanti in comune (predecessori comuni)
common_citing <- as.matrix(t(A) %*% A)
diag(common_citing) <- 0

# Aggiungi gli ID reali come nomi di righe e colonne
rownames(common_cited) <- V(graph)$name
colnames(common_cited) <- V(graph)$name

rownames(common_citing) <- V(graph)$name
colnames(common_citing) <- V(graph)$name



# Funzione per estrarre top N coppie
get_top_pairs <- function(mat, topn = 30) {
  # Prendi solo triangolo superiore
  mat[lower.tri(mat, diag = TRUE)] <- 0
  
  # Converti in formato "long"
  pairs <- which(mat > 0, arr.ind = TRUE)
  values <- mat[pairs]
  
  # Ordina e prendi top N
  top_idx <- order(values, decreasing = TRUE)[1:min(topn, length(values))]
  
  data.frame(
    paper_i = rownames(mat)[pairs[top_idx, 1]],
    paper_j = colnames(mat)[pairs[top_idx, 2]],
    shared = values[top_idx]
  )
}

# Top 30 coppie
top30_cited <- get_top_pairs(common_cited, 30)
top30_citing <- get_top_pairs(common_citing, 30)

head(top30_cited)
head(top30_citing)

```

Network delle Top 30 Coppie con Più Paper Citati in Comune.

```{r fig.width=12, fig.height=9, fig.align='center', warning=FALSE}

# Crea edge list dalle top 30 coppie
edges_cited <- top30_cited %>%
  select(from = paper_i, to = paper_j, weight = shared)

# Crea grafo
g_cited <- graph_from_data_frame(edges_cited, directed = FALSE)

ggraph(g_cited, layout = "fr") +
  geom_edge_link(aes(width = weight), alpha = 0.6) +
  geom_node_point(size = 5, color = "steelblue") +
  geom_node_text(aes(label = name), repel = TRUE, size = 3) +
  scale_edge_width(range = c(0.5, 3)) +
  labs(title = "Network delle Top 30 Coppie con Più Paper Citati in Comune") +
  theme_graph()


```


## 7 :  Identifica categorie potenti che non sono centrali e categorie centrali che non sono potenti.


```{r fig.width=12, fig.height=9, fig.align='center', warning=FALSE}

# Aggrega Katz e Power per categoria
category_stats <- data.frame(
  category = V(graph)$category,
  katz = katz,
  power = p
) %>%
  group_by(category) %>%
  summarise(
    avg_katz = mean(katz),
    avg_power = mean(power),
    n_papers = n()
  ) %>%
  ungroup()

# Calcola soglie
threshold_katz <- median(category_stats$avg_katz)
threshold_power <- median(category_stats$avg_power)

# Classifica le categorie nei 4 quadranti
category_stats <- category_stats %>%
  mutate(
    is_central = avg_katz > threshold_katz,
    is_powerful = avg_power > threshold_power,
    quadrant = case_when(
      is_central & is_powerful ~ "Central & Powerful",
      is_central & !is_powerful ~ "Central but NOT Powerful",
      !is_central & is_powerful ~ "Powerful but NOT Central",
      TRUE ~ "Neither Central nor Powerful"
    )
  )


ggplot(category_stats, aes(x = avg_katz, y = avg_power, color = quadrant)) +
  geom_point(size = 5) +
  geom_text(aes(label = category), vjust = -0.8, size = 3.5, color = "black") +
  geom_vline(xintercept = threshold_katz, linetype = "dashed", color = "gray50") +
  geom_hline(yintercept = threshold_power, linetype = "dashed", color = "gray50") +
  scale_color_manual(values = c(
    "Central & Powerful" = "darkgreen",
    "Central but NOT Powerful" = "blue",
    "Powerful but NOT Central" = "red",
    "Neither Central nor Powerful" = "gray60"
  )) +
  labs(
    x = "Average Katz Centrality",
    y = "Average Power Centrality",
    title = "Categorie: Katz (Centrale) vs Power (Potente)",
    color = "Quadrante"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")


```

## 8 : Visualizzare la rete tra categorie con la dimensione dei nodi proporzionale alla power e alla centralità, colore archi proporzionale al flusso di citazioni.


```{r fig.width=12, fig.height=9, fig.align='center', warning=FALSE}

# Crea matrice di citation flow tra categorie
categories <- sort(unique(V(graph)$category))
n_cat <- length(categories)

flow_matrix <- matrix(0, nrow = n_cat, ncol = n_cat)
rownames(flow_matrix) <- categories
colnames(flow_matrix) <- categories

# Ottieni edge list con indici numerici
edgelist <- get.edgelist(graph, names = FALSE)

# Ottieni categorie per ogni arco
from_categories <- V(graph)$category[edgelist[, 1]]
to_categories <- V(graph)$category[edgelist[, 2]]

# Popola la matrice (conta citazioni tra categorie)
for (i in 1:nrow(edgelist)) {
  from_cat <- from_categories[i]
  to_cat <- to_categories[i]
  flow_matrix[from_cat, to_cat] <- flow_matrix[from_cat, to_cat] + 1
}

# Elimino i Slf Loops
diag(flow_matrix) <- 0

# Crea grafo delle categorie con pesi
g_cat <- graph_from_adjacency_matrix(
  flow_matrix, 
  mode = "directed", 
  weighted = TRUE
)

# SEMPLIFICA: rimuove archi multipli e self-loops
g_cat <- simplify(g_cat, remove.multiple = TRUE, remove.loops = TRUE, 
                  edge.attr.comb = "sum")

# Assegna attributi
V(g_cat)$avg_katz <- category_stats$avg_katz[match(V(g_cat)$name, category_stats$category)]
V(g_cat)$avg_power <- category_stats$avg_power[match(V(g_cat)$name, category_stats$category)]

# Dimensioni nodi
V(g_cat)$size_katz <- 15 + 35 * (V(g_cat)$avg_katz / max(V(g_cat)$avg_katz))
V(g_cat)$size_power <- 15 + 35 * (V(g_cat)$avg_power / max(V(g_cat)$avg_power))

# Spessore archi proporzionale al peso
E(g_cat)$width <- 0.5 + 4 * E(g_cat)$weight / max(E(g_cat)$weight)

# Layout circolare
layout_cat <- layout_in_circle(g_cat)

# Normalizzo la Katz tra 0 e 1
V(g_cat)$avg_katz_norm <- (V(g_cat)$avg_katz - min(V(g_cat)$avg_katz)) / 
                          (max(V(g_cat)$avg_katz) - min(V(g_cat)$avg_katz))

# Normalizzo anche la Power 
V(g_cat)$avg_power_norm <- (V(g_cat)$avg_power - min(V(g_cat)$avg_power)) / 
                           (max(V(g_cat)$avg_power) - min(V(g_cat)$avg_power))

# Dimensioni nodi con valori normalizzati
V(g_cat)$size_katz <- 15 + 35 * V(g_cat)$avg_katz_norm
V(g_cat)$size_power <- 15 + 35 * V(g_cat)$avg_power_norm

# Classifica pesi archi e colori
weight_breaks <- quantile(E(g_cat)$weight, probs = seq(0, 1, 0.2))
E(g_cat)$weight_class <- cut(E(g_cat)$weight, 
                              breaks = weight_breaks, 
                              labels = c("Molto Basse", "Basse", "Medie", "Alte", "Molto Alte"),
                              include.lowest = TRUE)

edge_colors <- c("Molto Basse" = "#fee5d9", 
                 "Basse" = "#fcae91", 
                 "Medie" = "#fb6a4a", 
                 "Alte" = "#de2d26", 
                 "Molto Alte" = "#a50f15")

E(g_cat)$color <- edge_colors[E(g_cat)$weight_class]
E(g_cat)$width <- 1 + 5 * E(g_cat)$weight / max(E(g_cat)$weight)

```

Riprovo 
```{r fig.width=12, fig.height=9, fig.align='center', warning=FALSE}

# Crea matrice di citation flow tra categorie
categories <- sort(unique(V(graph)$category))
flow_matrix <- matrix(0, nrow = length(categories), ncol = length(categories),
                      dimnames = list(categories, categories))

# Popola la matrice contando le citazioni tra categorie
edgelist <- get.edgelist(graph, names = FALSE)
for (i in 1:nrow(edgelist)) {
  from_cat <- V(graph)$category[edgelist[i, 1]]
  to_cat <- V(graph)$category[edgelist[i, 2]]
  flow_matrix[from_cat, to_cat] <- flow_matrix[from_cat, to_cat] + 1
}
diag(flow_matrix) <- 0  # Elimina self-loops

# Crea grafo delle categorie
g_cat <- graph_from_adjacency_matrix(flow_matrix, mode = "directed", weighted = TRUE)
#g_cat <- simplify(g_cat)  # Rimuove automaticamente archi multipli e loops

# Assegna e normalizza Katz e Power
V(g_cat)$avg_katz <- category_stats$avg_katz[match(V(g_cat)$name, category_stats$category)]
V(g_cat)$avg_power <- category_stats$avg_power[match(V(g_cat)$name, category_stats$category)]

V(g_cat)$katz_norm <- (V(g_cat)$avg_katz - min(V(g_cat)$avg_katz)) /
                      (max(V(g_cat)$avg_katz) - min(V(g_cat)$avg_katz))
V(g_cat)$power_norm <- (V(g_cat)$avg_power - min(V(g_cat)$avg_power)) /
                       (max(V(g_cat)$avg_power) - min(V(g_cat)$avg_power))

# Dimensioni nodi normalizzate
V(g_cat)$size_katz <- 15 + 35 * V(g_cat)$katz_norm
V(g_cat)$size_power <- 15 + 35 * V(g_cat)$power_norm

# Colori e spessore archi basati sul peso
weight_breaks <- quantile(E(g_cat)$weight, probs = seq(0, 1, 0.2))
E(g_cat)$weight_class <- cut(E(g_cat)$weight, breaks = weight_breaks,
                              labels = c("Molto Basse", "Basse", "Medie", "Alte", "Molto Alte"),
                              include.lowest = TRUE)

edge_colors <- c("Molto Basse" = "#fee5d9", "Basse" = "#fcae91", "Medie" = "#fb6a4a",
                 "Alte" = "#de2d26", "Molto Alte" = "#a50f15")

E(g_cat)$color <- edge_colors[E(g_cat)$weight_class]
E(g_cat)$width <- 1 + 5 * E(g_cat)$weight / max(E(g_cat)$weight)

# Layout circolare
layout_cat <- layout_in_circle(g_cat)


```

```{r fig.width=12, fig.height=9, fig.align='center', warning=FALSE}

# PLOT 1: Katz - Valori normalizzati
plot(
  g_cat,
  vertex.size = V(g_cat)$size_katz,
  vertex.color = "steelblue",
  vertex.label = V(g_cat)$name,
  vertex.label.cex = 0.85,
  vertex.label.color = "black",
  vertex.label.dist = 0,
  vertex.frame.color = "black",
  edge.width = E(g_cat)$width,
  edge.arrow.size = 0.8,
  edge.color = E(g_cat)$color,
  edge.curved = 0.1,
  layout = layout_cat,
  main = "Network tra Categorie - Dimensione = Katz Centrality",
  margin = 0.1
)

# Legenda con valori fissi 0 e 1
legend("bottomleft",
       legend = c("Max Katz: 1.00", "Min Katz: 0.00"),
       pch = 21, pt.bg = "steelblue", pt.cex = c(2.5, 1), bty = "n",
       title = "Dimensione nodi (normalizzato)", cex = 1.1)

legend("topright",
       legend = names(edge_colors),
       col = edge_colors,
       lwd = 4,
       bty = "n",
       title = "Citation Flow",
       cex = 1.1)

# PLOT 2: Power - Valori normalizzati
plot(
  g_cat,
  vertex.size = V(g_cat)$size_power,
  vertex.color = "coral",
  vertex.label = V(g_cat)$name,
  vertex.label.cex = 0.85,
  vertex.label.color = "black",
  vertex.label.dist = 0,
  vertex.frame.color = "black",
  edge.width = E(g_cat)$width,
  edge.arrow.size = 0.8,
  edge.color = E(g_cat)$color,
  edge.curved = 0.1,
  layout = layout_cat,
  main = "Network tra Categorie - Dimensione = Power Centrality",
  margin = 0.1
)

# Legenda con valori fissi 0 e 1
legend("bottomleft",
       legend = c("Max Power: 1.00", "Min Power: 0.00"),
       pch = 21, pt.bg = "coral", pt.cex = c(2.5, 1), bty = "n",
       title = "Dimensione nodi (normalizzato)", cex = 1.1)

legend("topright",
       legend = names(edge_colors),
       col = edge_colors,
       lwd = 4,
       bty = "n",
       title = "Citation Flow",
       cex = 1.1)


```


## Salvataggio Metriche computate

```{r}

## Salvataggio Metriche computate

dir_processed <- "../data/processed"

if (!dir.exists(dir_processed)) {
  dir.create(dir_processed, recursive = TRUE)
}

# Salva il grafo completo con tutte le metriche di centralità
save(graph, file = file.path(dir_processed, "graph_with_centralities.RData"))

# Verifica attributi nodi salvati
cat("\n=== ATTRIBUTI NODI SALVATI ===\n")
cat(paste(vertex_attr_names(graph), collapse = ", "), "\n")

# Salva anche una versione CSV dei nodi per analisi esterne
nodes_data <- graph %>%
  activate(nodes) %>%
  as_tibble()

write.csv(nodes_data, 
          file.path(dir_processed, "nodes_with_centralities.csv"), 
          row.names = FALSE)

# Salva anche gli archi con attributi (se ne hai aggiunti)
edges_data <- graph %>%
  activate(edges) %>%
  as_tibble()

write.csv(edges_data,
          file.path(dir_processed, "edges_data.csv"),
          row.names = FALSE)

# Stampa riepilogo
cat("\n=== SALVATAGGIO COMPLETATO ===\n")
cat("✓ Grafo salvato in:", file.path(dir_processed, "graph_with_centralities.RData"), "\n")
cat("✓ Tabella nodi salvata in:", file.path(dir_processed, "nodes_with_centralities.csv"), "\n")
cat("✓ Tabella archi salvata in:", file.path(dir_processed, "edges_data.csv"), "\n")
cat("\n=== INFORMAZIONI GRAFO ===\n")
cat("  • Numero di nodi:", vcount(graph), "\n")
cat("  • Numero di archi:", ecount(graph), "\n")
cat("  • Numero di metriche calcolate:", length(vertex_attr_names(graph)) - 1, "\n")

```


## Appendix: Session Info

```{r}
sessionInfo()
```

